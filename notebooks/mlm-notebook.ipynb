{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13206554,"sourceType":"datasetVersion","datasetId":8370192}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport ast\nfrom tqdm import tqdm\nfrom collections import Counter\nimport datasets\nfrom datasets import (Dataset, Features, Sequence, Value, ClassLabel, load_dataset,\n                    load_from_disk, concatenate_datasets, DatasetDict)\nfrom sklearn.model_selection import KFold\nfrom transformers import (AutoTokenizer, AutoModel, AutoModelForTokenClassification,\n                         pipeline, PreTrainedTokenizerFast, TrainingArguments, Trainer,AutoModelForMaskedLM,\n                         DataCollatorForTokenClassification, EarlyStoppingCallback,\n                        DataCollatorForLanguageModeling, DataCollatorForWholeWordMask)\nimport torch\nimport optuna\nimport os\nos.environ['WANDB_DISABLED'] = 'true'\nimport pickle\nimport numpy as np\n\nfrom typing import List, Optional\nimport random\nseed=42\nrandom.seed(seed)\n\nimport math\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:28:36.164410Z","iopub.execute_input":"2025-09-30T07:28:36.164713Z","iopub.status.idle":"2025-09-30T07:29:22.067150Z","shell.execute_reply.started":"2025-09-30T07:28:36.164689Z","shell.execute_reply":"2025-09-30T07:29:22.066557Z"}},"outputs":[{"name":"stderr","text":"2025-09-30 07:29:02.040712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759217342.361204      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759217342.456681      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df_mlm = pd.read_csv('/kaggle/input/mlm-v1/augmented_dataset_mlm.csv')\ndf_mlm.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:22.068445Z","iopub.execute_input":"2025-09-30T07:29:22.069000Z","iopub.status.idle":"2025-09-30T07:29:22.997910Z","shell.execute_reply.started":"2025-09-30T07:29:22.068979Z","shell.execute_reply":"2025-09-30T07:29:22.997087Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(188060, 3)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df = df_mlm.iloc[::4]\ndf.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:22.998778Z","iopub.execute_input":"2025-09-30T07:29:22.999062Z","iopub.status.idle":"2025-09-30T07:29:23.004686Z","shell.execute_reply.started":"2025-09-30T07:29:22.999037Z","shell.execute_reply":"2025-09-30T07:29:23.003781Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(47015, 3)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"model_name_or_path = \"numind/NuNER-multilingual-v0.1\"\nmodel = AutoModelForMaskedLM.from_pretrained(model_name_or_path)\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:29.434614Z","iopub.execute_input":"2025-09-30T07:29:29.434898Z","iopub.status.idle":"2025-09-30T07:29:35.485256Z","shell.execute_reply.started":"2025-09-30T07:29:29.434878Z","shell.execute_reply":"2025-09-30T07:29:35.484638Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a1a05fd4dcb4c1bac08ffd3c0030427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83173eb117b5445dbaa869367a6e6abd"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForMaskedLM were not initialized from the model checkpoint at numind/NuNER-multilingual-v0.1 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/360 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6bdfa55f37a4cb59669b9e8217d3e78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85cc97f894914c7bb9d442e78d84c4b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a52661b0ed451e92fdf98de189551f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac633b573b0b409dbabf325a5744a1b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24281b750d41496687826e41655fde43"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def mix_and_subsample(originals: List[str], augmented: List[str], mix_ratio: float = 0.75, seed: int = 42) -> List[str]:\n    # mix_ratio = fraction of examples from originals\n    random.seed(seed)\n    n_total = len(originals) + len(augmented)\n    n_from_orig = int(n_total * mix_ratio)\n    n_from_aug = n_total - n_from_orig\n\n    chosen_orig = random.choices(originals, k=max(1, n_from_orig)) if originals else []\n    chosen_aug = random.choices(augmented, k=max(1, n_from_aug)) if augmented else []\n    combined = chosen_orig + chosen_aug\n    random.shuffle(combined)\n    return combined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:35.486359Z","iopub.execute_input":"2025-09-30T07:29:35.486590Z","iopub.status.idle":"2025-09-30T07:29:35.491471Z","shell.execute_reply.started":"2025-09-30T07:29:35.486565Z","shell.execute_reply":"2025-09-30T07:29:35.490904Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def tokenize_and_group_texts(lines: List[str], tokenizer: PreTrainedTokenizerFast, block_size: int = 32, use_wwm: bool = False, seed=42):\n    \"\"\"Tokenize lines and group into blocks of `block_size`. If use_wwm=True we use is_split_into_words approach.\n\n    Returns a HuggingFace Dataset with columns 'input_ids' and 'labels'\n    \"\"\"\n    # Build dataset\n    ds = Dataset.from_dict({'text': lines})\n\n    def tokenize_func(examples):\n        if use_wwm:\n            # split into whitespace tokens for whole-word masking\n            words = [t.split() for t in examples['text']]\n            return tokenizer(words, is_split_into_words=True, add_special_tokens=True)\n        else:\n            return tokenizer(examples['text'], add_special_tokens=True)\n\n    tokenized = ds.map(tokenize_func, batched=True, remove_columns=['text'])\n\n    # concatenate and group\n    def group_texts(examples):\n        concatenated = sum(examples['input_ids'], [])\n        total_length = len(concatenated)\n        if total_length >= block_size:\n            total_length = (total_length // block_size) * block_size\n        else:\n            total_length = 0\n        result = {}\n        if total_length == 0:\n            result['input_ids'] = []\n            result['labels'] = []\n            return result\n        result['input_ids'] = [concatenated[i:i+block_size] for i in range(0, total_length, block_size)]\n        result['labels'] = [list(ids) for ids in result['input_ids']]\n        return result\n\n    lm_dataset = tokenized.map(group_texts, batched=True, remove_columns=tokenized.column_names)\n    # drop empty rows\n    lm_dataset = lm_dataset.filter(lambda ex: len(ex['input_ids']) > 0)\n\n    # train/val split\n    split = lm_dataset.train_test_split(test_size=0.01, seed=seed)\n    return DatasetDict({'train': split['train'], 'validation': split['test']})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:44.869646Z","iopub.execute_input":"2025-09-30T07:29:44.869912Z","iopub.status.idle":"2025-09-30T07:29:44.878001Z","shell.execute_reply.started":"2025-09-30T07:29:44.869894Z","shell.execute_reply":"2025-09-30T07:29:44.877238Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def build_data_collator(tokenizer: PreTrainedTokenizerFast, use_wwm: bool = False, mlm_probability: float = 0.15):\n    if use_wwm:\n        # DataCollatorForWholeWordMask expects tokenizer with word_ids support\n        return DataCollatorForWholeWordMask(tokenizer=tokenizer, mlm=True, mlm_probability=mlm_probability)\n    else:\n        return DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=mlm_probability)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:48.826443Z","iopub.execute_input":"2025-09-30T07:29:48.827013Z","iopub.status.idle":"2025-09-30T07:29:48.831375Z","shell.execute_reply.started":"2025-09-30T07:29:48.826991Z","shell.execute_reply":"2025-09-30T07:29:48.830563Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"use_wwm = True\noutput_dir = \"./results_ft\"\nnum_epochs=5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:50.480916Z","iopub.execute_input":"2025-09-30T07:29:50.481554Z","iopub.status.idle":"2025-09-30T07:29:50.484985Z","shell.execute_reply.started":"2025-09-30T07:29:50.481529Z","shell.execute_reply":"2025-09-30T07:29:50.484401Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"os.makedirs(output_dir, exist_ok=True)\nrandom.seed(seed)\n\noriginals = df['original'].tolist()\naugmented = df['variant'].tolist()\n\n\n# # Basic exploration\n# print('Exploring data distributions...')\n# s_orig = simple_text_stats(originals) if originals else {}\n# s_aug = simple_text_stats(augmented) if augmented else {}\n# print('Originals stats:', json.dumps(s_orig, ensure_ascii=False, indent=2))\n# print('Augmented stats:', json.dumps(s_aug, ensure_ascii=False, indent=2))\n\n# Combine corpus according to mix_ratio\ncombined = mix_and_subsample(originals, augmented, mix_ratio=0.75, seed=seed)\nprint(f'Combined corpus size: {len(combined)}')\n\n# Tokenizer\n# tokenizer = None\n# tokenizer_path = os.path.join(\".\", 'tokenizer.json')\nprint(f'Loading tokenizer from pretrained model: \"{model_name_or_path}\"')\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path, do_lower_case=True)\n# ensure mask token exists\n# if tokenizer.mask_token is None:\n#     tokenizer.add_special_tokens({'mask_token': '[MASK]'})\n\n# Tokenize and group\ntokenized_ds = tokenize_and_group_texts(combined, tokenizer, use_wwm=use_wwm)\nprint('Train examples (blocks):', len(tokenized_ds['train']))\nprint('Validation examples (blocks):', len(tokenized_ds['validation']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:29:51.207215Z","iopub.execute_input":"2025-09-30T07:29:51.207846Z","iopub.status.idle":"2025-09-30T07:30:05.724306Z","shell.execute_reply.started":"2025-09-30T07:29:51.207822Z","shell.execute_reply":"2025-09-30T07:30:05.723320Z"}},"outputs":[{"name":"stdout","text":"Combined corpus size: 94030\nLoading tokenizer from pretrained model: \"numind/NuNER-multilingual-v0.1\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/94030 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46e02b3d872a4b8cb7e5a22f1db83b88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/94030 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ec2d4951cd74cf5a84a31041519329d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/66960 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e033db15b1d84f19a0a084cd69d08a20"}},"metadata":{}},{"name":"stdout","text":"Train examples (blocks): 66290\nValidation examples (blocks): 670\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"tokenized_ds[\"train\"].select(range(10)).to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:13:14.171776Z","iopub.execute_input":"2025-09-30T07:13:14.172398Z","iopub.status.idle":"2025-09-30T07:13:14.203019Z","shell.execute_reply.started":"2025-09-30T07:13:14.172372Z","shell.execute_reply":"2025-09-30T07:13:14.202219Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0  [50298, 40643, 11307, 10191, 13012, 10868, 104...   \n1  [80062, 36694, 10648, 543, 97744, 54453, 12265...   \n2  [10123, 10191, 117, 18302, 10241, 10517, 102, ...   \n3  [10191, 85710, 10656, 67482, 108276, 117, 122,...   \n4  [10332, 94383, 14708, 10241, 14208, 557, 13157...   \n5  [101, 551, 17961, 91680, 10179, 14816, 55399, ...   \n6  [30977, 10241, 31399, 88535, 76316, 12868, 103...   \n7  [50154, 117, 14048, 10823, 102, 101, 10122, 80...   \n8  [10757, 10241, 10517, 102, 101, 11279, 40703, ...   \n9  [10196, 77202, 31066, 553, 69605, 12202, 10191...   \n\n                                              labels  \n0  [50298, 40643, 11307, 10191, 13012, 10868, 104...  \n1  [80062, 36694, 10648, 543, 97744, 54453, 12265...  \n2  [10123, 10191, 117, 18302, 10241, 10517, 102, ...  \n3  [10191, 85710, 10656, 67482, 108276, 117, 122,...  \n4  [10332, 94383, 14708, 10241, 14208, 557, 13157...  \n5  [101, 551, 17961, 91680, 10179, 14816, 55399, ...  \n6  [30977, 10241, 31399, 88535, 76316, 12868, 103...  \n7  [50154, 117, 14048, 10823, 102, 101, 10122, 80...  \n8  [10757, 10241, 10517, 102, 101, 11279, 40703, ...  \n9  [10196, 77202, 31066, 553, 69605, 12202, 10191...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[50298, 40643, 11307, 10191, 13012, 10868, 104...</td>\n      <td>[50298, 40643, 11307, 10191, 13012, 10868, 104...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[80062, 36694, 10648, 543, 97744, 54453, 12265...</td>\n      <td>[80062, 36694, 10648, 543, 97744, 54453, 12265...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[10123, 10191, 117, 18302, 10241, 10517, 102, ...</td>\n      <td>[10123, 10191, 117, 18302, 10241, 10517, 102, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[10191, 85710, 10656, 67482, 108276, 117, 122,...</td>\n      <td>[10191, 85710, 10656, 67482, 108276, 117, 122,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[10332, 94383, 14708, 10241, 14208, 557, 13157...</td>\n      <td>[10332, 94383, 14708, 10241, 14208, 557, 13157...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[101, 551, 17961, 91680, 10179, 14816, 55399, ...</td>\n      <td>[101, 551, 17961, 91680, 10179, 14816, 55399, ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[30977, 10241, 31399, 88535, 76316, 12868, 103...</td>\n      <td>[30977, 10241, 31399, 88535, 76316, 12868, 103...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[50154, 117, 14048, 10823, 102, 101, 10122, 80...</td>\n      <td>[50154, 117, 14048, 10823, 102, 101, 10122, 80...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[10757, 10241, 10517, 102, 101, 11279, 40703, ...</td>\n      <td>[10757, 10241, 10517, 102, 101, 11279, 40703, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[10196, 77202, 31066, 553, 69605, 12202, 10191...</td>\n      <td>[10196, 77202, 31066, 553, 69605, 12202, 10191...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"tokenizer.tokenize(\"как делать [MASK]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:13:59.216706Z","iopub.execute_input":"2025-09-30T07:13:59.217349Z","iopub.status.idle":"2025-09-30T07:13:59.222619Z","shell.execute_reply.started":"2025-09-30T07:13:59.217316Z","shell.execute_reply":"2025-09-30T07:13:59.221932Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['как', 'дела', '##ть', '[MASK]']"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"tokenizer.encode(\"как делать [MASK]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:14:25.343195Z","iopub.execute_input":"2025-09-30T07:14:25.343929Z","iopub.status.idle":"2025-09-30T07:14:25.349638Z","shell.execute_reply.started":"2025-09-30T07:14:25.343876Z","shell.execute_reply":"2025-09-30T07:14:25.348883Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[101, 10949, 25195, 11258, 103, 102]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"tokenizer.decode(tokenized_ds[\"train\"].select(range(10)).to_pandas()['input_ids'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:20:23.692722Z","iopub.execute_input":"2025-09-30T07:20:23.693309Z","iopub.status.idle":"2025-09-30T07:20:23.703400Z","shell.execute_reply.started":"2025-09-30T07:20:23.693285Z","shell.execute_reply":"2025-09-30T07:20:23.702774Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'##азированныи без сахар, 50г [SEP] [CLS] хлебцы take a bieт ккууризhо - рсиоы'"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Model\nprint('Loading model...')\nmodel = AutoModelForMaskedLM.from_pretrained(model_name_or_path)\n# # if tokenizer added tokens, resize\n# try:\n#     model.resize_token_embeddings(len(tokenizer))\n# except Exception:\n#     pass\n\n# Data collator\ndata_collator = build_data_collator(tokenizer, use_wwm=use_wwm, mlm_probability=0.2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:30:08.385232Z","iopub.execute_input":"2025-09-30T07:30:08.386079Z","iopub.status.idle":"2025-09-30T07:30:09.240506Z","shell.execute_reply.started":"2025-09-30T07:30:08.386052Z","shell.execute_reply":"2025-09-30T07:30:09.239914Z"}},"outputs":[{"name":"stdout","text":"Loading model...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForMaskedLM were not initialized from the model checkpoint at numind/NuNER-multilingual-v0.1 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# collated_batch = data_collator(tokenized_ds[\"train\"].select(range(10)))\n# print(collated_batch['input_ids'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:30:15.495308Z","iopub.execute_input":"2025-09-30T07:30:15.495657Z","iopub.status.idle":"2025-09-30T07:30:15.499020Z","shell.execute_reply.started":"2025-09-30T07:30:15.495636Z","shell.execute_reply":"2025-09-30T07:30:15.498399Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"tokenizer.decode(collated_batch['input_ids'][2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:24:57.101681Z","iopub.execute_input":"2025-09-30T07:24:57.101991Z","iopub.status.idle":"2025-09-30T07:24:57.107190Z","shell.execute_reply.started":"2025-09-30T07:24:57.101965Z","shell.execute_reply":"2025-09-30T07:24:57.106525Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'omtalt [MASK], 270мл [SEP] [CLS] печенье lotte choco pie [MASK] [MASK] [MASK] [MASK] глазированное, 336г [SEP] [CLS] перчат'"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"\n# Training args\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_epochs,\n    per_device_train_batch_size=128,\n    gradient_accumulation_steps=1,\n    eval_strategy=\"steps\",    # evaluate by steps\n    eval_steps=200,                 # every 200 steps\n\n    logging_strategy=\"steps\",       # log by steps\n    logging_steps=200,\n\n    save_strategy=\"epoch\",          # save by epoch\n    save_total_limit=num_epochs,    # keep last N checkpoints (can also set smaller)\n    learning_rate=3e-5,\n    weight_decay=0.01,\n    seed=seed,\n    fp16=False,\n    report_to='none',\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized_ds['train'],\n    eval_dataset=tokenized_ds['validation'],\n)\n\n# Train\nprint('Starting training...')\ntrainer.train()\n\n# Eval\nprint('Running final evaluation...')\nmetrics = trainer.evaluate()\nloss = metrics.get('eval_loss')\nif loss is not None:\n    try:\n        ppl = math.exp(loss)\n    except OverflowError:\n        ppl = float('inf')\n    metrics['perplexity'] = ppl\nprint('Eval metrics:', metrics)\n\n# Save\nprint('Saving tokenizer and model...')\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\nprint('Done. Model saved to', output_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T07:30:25.736079Z","iopub.execute_input":"2025-09-30T07:30:25.736589Z","iopub.status.idle":"2025-09-30T08:16:22.180912Z","shell.execute_reply.started":"2025-09-30T07:30:25.736564Z","shell.execute_reply":"2025-09-30T08:16:22.180067Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1295' max='1295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1295/1295 45:43, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.689400</td>\n      <td>4.722475</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>4.586500</td>\n      <td>4.259158</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>4.280500</td>\n      <td>4.025820</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>4.122500</td>\n      <td>3.917448</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>4.007600</td>\n      <td>3.822100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.927000</td>\n      <td>3.779876</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Running final evaluation...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [42/42 00:05]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Eval metrics: {'eval_loss': 3.9210193157196045, 'eval_runtime': 6.1764, 'eval_samples_per_second': 108.478, 'eval_steps_per_second': 6.8, 'epoch': 5.0, 'perplexity': 50.45184493574677}\nSaving tokenizer and model...\nDone. Model saved to ./results_ft\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"model == trainer.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:52:45.830705Z","iopub.status.idle":"2025-09-29T13:52:45.830984Z","shell.execute_reply.started":"2025-09-29T13:52:45.830818Z","shell.execute_reply":"2025-09-29T13:52:45.830841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_mlm.sample().original.iloc[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:20:16.575953Z","iopub.execute_input":"2025-09-30T08:20:16.576585Z","iopub.status.idle":"2025-09-30T08:20:16.585791Z","shell.execute_reply.started":"2025-09-30T08:20:16.576552Z","shell.execute_reply":"2025-09-30T08:20:16.585176Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'игристое вино мысхако русток феркаль кубань белое полусухое, 750мл'"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"maska = \"[MASK]\"\ntext = f'игристое вино мысхако русток феркаль {maska} белое полусухое, 750мл'\n\ninputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\ntoken_logits = model(**inputs).logits\n# Find the location of [MASK] and extract its logits\nmask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\nmask_token_logits = token_logits[0, mask_token_index, :]\n# Pick the [MASK] candidates with the highest logits\ntop_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n\nfor token in top_5_tokens:\n    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:20:30.422322Z","iopub.execute_input":"2025-09-30T08:20:30.423029Z","iopub.status.idle":"2025-09-30T08:20:30.444845Z","shell.execute_reply.started":"2025-09-30T08:20:30.423008Z","shell.execute_reply":"2025-09-30T08:20:30.444273Z"}},"outputs":[{"name":"stdout","text":"'>>> игристое вино мысхако русток феркаль село белое полусухое, 750мл'\n'>>> игристое вино мысхако русток феркаль ##ное белое полусухое, 750мл'\n'>>> игристое вино мысхако русток феркаль , белое полусухое, 750мл'\n'>>> игристое вино мысхако русток феркаль select белое полусухое, 750мл'\n'>>> игристое вино мысхако русток феркаль ##е белое полусухое, 750мл'\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/rubert_tiny2_MLM_290925\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:52:45.834300Z","iopub.status.idle":"2025-09-29T13:52:45.834935Z","shell.execute_reply.started":"2025-09-29T13:52:45.834802Z","shell.execute_reply":"2025-09-29T13:52:45.834815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(tokenizer, \"/kaggle/working/rubert_tiny2_MLM_290925_tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:52:45.835602Z","iopub.status.idle":"2025-09-29T13:52:45.835795Z","shell.execute_reply.started":"2025-09-29T13:52:45.835704Z","shell.execute_reply":"2025-09-29T13:52:45.835712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"my_mlm_checkpoint\")\ntokenizer.save_pretrained(\"my_mlm_checkpoint\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:52:45.836912Z","iopub.status.idle":"2025-09-29T13:52:45.837404Z","shell.execute_reply.started":"2025-09-29T13:52:45.837241Z","shell.execute_reply":"2025-09-29T13:52:45.837256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:20:42.426239Z","iopub.execute_input":"2025-09-30T08:20:42.427009Z","iopub.status.idle":"2025-09-30T08:20:42.542566Z","shell.execute_reply.started":"2025-09-30T08:20:42.426981Z","shell.execute_reply":"2025-09-30T08:20:42.542032Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"MLM по выборке названий продуктов nuner\")  # Explicitly push if not done automatically","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:20:49.138849Z","iopub.execute_input":"2025-09-30T08:20:49.139208Z","iopub.status.idle":"2025-09-30T08:21:03.368756Z","shell.execute_reply.started":"2025-09-30T08:20:49.139177Z","shell.execute_reply":"2025-09-30T08:21:03.368020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading...:   0%|          | 0.00/712M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"200019eeaf3e41d090509a36ccd329b9"}},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Dersty/results_ft/commit/51f2aa01066f9feb30e163ee5c1f981a18197c8c', commit_message='MLM по выборке названий продуктов nuner', commit_description='', oid='51f2aa01066f9feb30e163ee5c1f981a18197c8c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Dersty/results_ft', endpoint='https://huggingface.co', repo_type='model', repo_id='Dersty/results_ft'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}