{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a5b0e7638d6d4c4ca0996d7b020e59d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9d7f068b3b1456b94729031bf250e94","IPY_MODEL_3a24111dace7456a9e37fbb60d04c38b","IPY_MODEL_35d94b59d14549b5b9d86553a348e420"],"layout":"IPY_MODEL_7479e69dcd50435e884e334cc0cf38ee"}},"c9d7f068b3b1456b94729031bf250e94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_174e223ef4a945579f9eb7f4ae0e93e4","placeholder":"​","style":"IPY_MODEL_d79c62114fd142029255e0db1d52ed9a","value":"config.json: "}},"3a24111dace7456a9e37fbb60d04c38b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f96b1b42a7e44816852f51b36e39dd09","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_833566aa83484331b5c11dfdb7f21ee9","value":1}},"35d94b59d14549b5b9d86553a348e420":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e1f4410c4f4c3d8cc06c0157a03af7","placeholder":"​","style":"IPY_MODEL_74ccad71321d41cea860aaefec83502d","value":" 1.37k/? [00:00&lt;00:00, 38.3kB/s]"}},"7479e69dcd50435e884e334cc0cf38ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"174e223ef4a945579f9eb7f4ae0e93e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79c62114fd142029255e0db1d52ed9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f96b1b42a7e44816852f51b36e39dd09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"833566aa83484331b5c11dfdb7f21ee9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52e1f4410c4f4c3d8cc06c0157a03af7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74ccad71321d41cea860aaefec83502d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5beb6f270e544ad3b5f2b9edd2605a5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc0a360c3f2a4aaeb70b1885824fa0e1","IPY_MODEL_f908bd7798154697a9ff049ae264d9fb","IPY_MODEL_4d28a06aede948a294baaf885731bb09"],"layout":"IPY_MODEL_64d1aa0086b84b87bc7a92e0c58eef1c"}},"fc0a360c3f2a4aaeb70b1885824fa0e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a07ea51a1d4e8d80962661675ea36e","placeholder":"​","style":"IPY_MODEL_bafb54e447c648a5882908f01813707d","value":"pytorch_model.bin: 100%"}},"f908bd7798154697a9ff049ae264d9fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f74a6c9f08894d0d9d1aefa18dc2ac17","max":2950830248,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7de1fa7fcd614b418298905d6ec4f797","value":2950830248}},"4d28a06aede948a294baaf885731bb09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d75f429947524e71ab02959544ba3c61","placeholder":"​","style":"IPY_MODEL_854e9b2131e945f69fea27cbcea4c144","value":" 2.95G/2.95G [01:15&lt;00:00, 39.3MB/s]"}},"64d1aa0086b84b87bc7a92e0c58eef1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a07ea51a1d4e8d80962661675ea36e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bafb54e447c648a5882908f01813707d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f74a6c9f08894d0d9d1aefa18dc2ac17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de1fa7fcd614b418298905d6ec4f797":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d75f429947524e71ab02959544ba3c61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"854e9b2131e945f69fea27cbcea4c144":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd16b83691fd460e8cd07c0dd51a8aa2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a3cb4e7e20d461db1e9a97415ed9e7c","IPY_MODEL_b3bc82a5af874c27a57e117569aba3f0","IPY_MODEL_1a2717f60ca9484abbafb785df3faa46"],"layout":"IPY_MODEL_0ea90c0f92c4414c8f93a554a74cfab1"}},"6a3cb4e7e20d461db1e9a97415ed9e7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9287aa5abe4746128c2eeb1a4547a61a","placeholder":"​","style":"IPY_MODEL_a1cdb359996b4942ad1b416fbd747e97","value":"model.safetensors: 100%"}},"b3bc82a5af874c27a57e117569aba3f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2efdb87c7844176991e0906f1f183dc","max":2950734664,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae82b099a4f143e38d82feb76211b8fb","value":2950734664}},"1a2717f60ca9484abbafb785df3faa46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43fdcf9676544621b741aa7ad751f621","placeholder":"​","style":"IPY_MODEL_dc799160c3714d9087f92c71c5bf79e2","value":" 2.95G/2.95G [03:04&lt;00:00, 18.5MB/s]"}},"0ea90c0f92c4414c8f93a554a74cfab1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9287aa5abe4746128c2eeb1a4547a61a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1cdb359996b4942ad1b416fbd747e97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2efdb87c7844176991e0906f1f183dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae82b099a4f143e38d82feb76211b8fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43fdcf9676544621b741aa7ad751f621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc799160c3714d9087f92c71c5bf79e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"219043a57bd8424c8a3ccf0c1a54115c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50329a055e564b429c0c2c3e81f08272","IPY_MODEL_7fd98312f8c94562b016b924a38efc80","IPY_MODEL_31657f0e1130493d9faa5511f648fa53"],"layout":"IPY_MODEL_4bc7b0ae0c4b4685bbcc941601390f78"}},"50329a055e564b429c0c2c3e81f08272":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d05042af89454f91ba8bdf52d85f11fd","placeholder":"​","style":"IPY_MODEL_57c2910ccdfb47eeb7c1645e82778573","value":"Map: 100%"}},"7fd98312f8c94562b016b924a38efc80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ebf79726ab40eaa1ac7fc99e0a38ce","max":20438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1f3799d8ade4c3981ddce11e76a0fcd","value":20438}},"31657f0e1130493d9faa5511f648fa53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0366d2f2ee7c4c4b9621c3afd5e75f23","placeholder":"​","style":"IPY_MODEL_4dbe44cb63504cc6b81778510201e2e3","value":" 20438/20438 [00:01&lt;00:00, 9777.39 examples/s]"}},"4bc7b0ae0c4b4685bbcc941601390f78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d05042af89454f91ba8bdf52d85f11fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57c2910ccdfb47eeb7c1645e82778573":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ebf79726ab40eaa1ac7fc99e0a38ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1f3799d8ade4c3981ddce11e76a0fcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0366d2f2ee7c4c4b9621c3afd5e75f23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dbe44cb63504cc6b81778510201e2e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d76a2f0f26d7457cb26bebde30ed5e0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c117ffca9f6b4146b305b558f7939847","IPY_MODEL_dc094b00dec74afb802ee7d6df12c1be","IPY_MODEL_374bb6ddc4a64823b2cfdd327864a953"],"layout":"IPY_MODEL_b32f39249a974519ba3b1fd956c53276"}},"c117ffca9f6b4146b305b558f7939847":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1e6420c5c4b409980a2a951dad44dd8","placeholder":"​","style":"IPY_MODEL_87b888ce920d454dad4945fa26643fe8","value":"Map: 100%"}},"dc094b00dec74afb802ee7d6df12c1be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_259f9f4db413414a823a1a3f241a98a7","max":6813,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e340cbd6da544828ce8609fb500945d","value":6813}},"374bb6ddc4a64823b2cfdd327864a953":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56093491341a4bf39bfe7b09fdd41e86","placeholder":"​","style":"IPY_MODEL_a25d768bb6cd45b18999ede839a8428c","value":" 6813/6813 [00:00&lt;00:00, 17425.11 examples/s]"}},"b32f39249a974519ba3b1fd956c53276":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e6420c5c4b409980a2a951dad44dd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87b888ce920d454dad4945fa26643fe8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"259f9f4db413414a823a1a3f241a98a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e340cbd6da544828ce8609fb500945d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56093491341a4bf39bfe7b09fdd41e86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a25d768bb6cd45b18999ede839a8428c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13177364,"sourceType":"datasetVersion","datasetId":8350299},{"sourceId":13178124,"sourceType":"datasetVersion","datasetId":8350857},{"sourceId":13178161,"sourceType":"datasetVersion","datasetId":8350889},{"sourceId":590906,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":442003,"modelId":458554}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install optuna seqeval evaluate -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJsYu1XI0I1c","outputId":"5de3e6d3-3882-4c99-b7e0-a03fdc9906c8","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:23:49.161641Z","iopub.execute_input":"2025-09-26T14:23:49.161862Z","iopub.status.idle":"2025-09-26T14:23:56.374833Z","shell.execute_reply.started":"2025-09-26T14:23:49.161846Z","shell.execute_reply":"2025-09-26T14:23:56.373929Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport ast\nfrom tqdm import tqdm\nfrom collections import Counter\nimport datasets\nfrom datasets import (Dataset, Features, Sequence, Value, ClassLabel, load_dataset,\n                    load_from_disk, concatenate_datasets, DatasetDict)\nfrom sklearn.model_selection import KFold\nfrom transformers import (AutoTokenizer, AutoModel, AutoModelForTokenClassification,\n                         pipeline, TrainingArguments, Trainer,\n                         DataCollatorForTokenClassification, EarlyStoppingCallback)\nimport torch\nimport optuna\nimport os\nos.environ['WANDB_DISABLED'] = 'true'\nimport pickle\nimport numpy as np\nimport seqeval\nimport evaluate\nfrom seqeval.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n\nseqeval = evaluate.load(\"seqeval\")","metadata":{"id":"_88EgnsXmkyw","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:53:39.137461Z","iopub.execute_input":"2025-09-26T14:53:39.138092Z","iopub.status.idle":"2025-09-26T14:53:39.643934Z","shell.execute_reply.started":"2025-09-26T14:53:39.138072Z","shell.execute_reply":"2025-09-26T14:53:39.643431Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive', force_remount=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0vpcj2O3kaP","outputId":"44dd6115-274c-45f8-d1dd-3d2ac5b596ad","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:00:12.689495Z","iopub.execute_input":"2025-09-26T13:00:12.689973Z","iopub.status.idle":"2025-09-26T13:00:12.693641Z","shell.execute_reply.started":"2025-09-26T13:00:12.689954Z","shell.execute_reply":"2025-09-26T13:00:12.693015Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"TRAIN_PATH_COLAB = \"/content/drive/MyDrive/Hackatons/X5_ner_2025/train.csv\"\nSUBMISSION_PATH_COLAB = \"/content/drive/MyDrive/Hackatons/X5_ner_2025/submission.csv\"\nTRAIN_PATH_KAGGLE = \"/kaggle/input/x5-ner-train/train.csv\"\nTRAIN_AUGMENTED = \"/kaggle/input/train-augmented-col-perc/train_with_augmented_volume_percent.csv\"","metadata":{"id":"g1wqNoXHKQ4p","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:24:48.940358Z","iopub.execute_input":"2025-09-26T14:24:48.941317Z","iopub.status.idle":"2025-09-26T14:24:48.945488Z","shell.execute_reply.started":"2025-09-26T14:24:48.941283Z","shell.execute_reply":"2025-09-26T14:24:48.944739Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## IN","metadata":{}},{"cell_type":"markdown","source":"## Подготовка датасета","metadata":{"id":"_mL7LN0QnulJ"}},{"cell_type":"code","source":"train_df_raw = pd.read_csv(TRAIN_AUGMENTED, sep=';')\ntrain_df_raw","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ScdZI8e5nmIi","outputId":"bb2bf9a7-c117-47db-c321-516f2b9e51a0","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:45.180426Z","iopub.execute_input":"2025-09-26T14:25:45.180704Z","iopub.status.idle":"2025-09-26T14:25:45.258114Z","shell.execute_reply.started":"2025-09-26T14:25:45.180682Z","shell.execute_reply":"2025-09-26T14:25:45.257365Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                       sample  \\\n0                          aa   \n1                        aala   \n2                      aarcca   \n3                        abon   \n4                        abso   \n...                       ...   \n27547  ветчина 300 гр нарезка   \n27548   кукуруза 400 г mikado   \n27549         кукуруза 340 гр   \n27550     хлеб 350 г 5 злаков   \n27551       хлеб 500 гр злаки   \n\n                                              annotation  \n0                                          [(0, 2, 'O')]  \n1                                          [(0, 4, 'O')]  \n2                                          [(0, 6, 'O')]  \n3                                          [(0, 4, 'O')]  \n4                                    [(0, 4, 'B-BRAND')]  \n...                                                  ...  \n27547  [(0, 7, 'B-TYPE'), (8, 11, 'B-VOLUME'), (12, 1...  \n27548  [(0, 8, 'B-TYPE'), (9, 12, 'B-VOLUME'), (13, 1...  \n27549  [(0, 8, 'B-TYPE'), (9, 12, 'B-VOLUME'), (13, 1...  \n27550  [(0, 4, 'B-TYPE'), (5, 8, 'B-VOLUME'), (9, 10,...  \n27551  [(0, 4, 'B-TYPE'), (5, 8, 'B-VOLUME'), (9, 11,...  \n\n[27552 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>annotation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aa</td>\n      <td>[(0, 2, 'O')]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aala</td>\n      <td>[(0, 4, 'O')]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aarcca</td>\n      <td>[(0, 6, 'O')]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abon</td>\n      <td>[(0, 4, 'O')]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abso</td>\n      <td>[(0, 4, 'B-BRAND')]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27547</th>\n      <td>ветчина 300 гр нарезка</td>\n      <td>[(0, 7, 'B-TYPE'), (8, 11, 'B-VOLUME'), (12, 1...</td>\n    </tr>\n    <tr>\n      <th>27548</th>\n      <td>кукуруза 400 г mikado</td>\n      <td>[(0, 8, 'B-TYPE'), (9, 12, 'B-VOLUME'), (13, 1...</td>\n    </tr>\n    <tr>\n      <th>27549</th>\n      <td>кукуруза 340 гр</td>\n      <td>[(0, 8, 'B-TYPE'), (9, 12, 'B-VOLUME'), (13, 1...</td>\n    </tr>\n    <tr>\n      <th>27550</th>\n      <td>хлеб 350 г 5 злаков</td>\n      <td>[(0, 4, 'B-TYPE'), (5, 8, 'B-VOLUME'), (9, 10,...</td>\n    </tr>\n    <tr>\n      <th>27551</th>\n      <td>хлеб 500 гр злаки</td>\n      <td>[(0, 4, 'B-TYPE'), (5, 8, 'B-VOLUME'), (9, 11,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>27552 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_df_raw['annotation'] = train_df_raw['annotation'].str.replace(\"\\'0\\'\", \"O\")","metadata":{"id":"nDQgR80T2J1s","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:46.043315Z","iopub.execute_input":"2025-09-26T14:25:46.043606Z","iopub.status.idle":"2025-09-26T14:25:46.059029Z","shell.execute_reply.started":"2025-09-26T14:25:46.043585Z","shell.execute_reply":"2025-09-26T14:25:46.058112Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_df_raw['annotation'] = train_df_raw['annotation'].apply(lambda x: ast.literal_eval(str(x)))","metadata":{"id":"mIms8O__rRtw","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:47.941252Z","iopub.execute_input":"2025-09-26T14:25:47.941925Z","iopub.status.idle":"2025-09-26T14:25:48.319302Z","shell.execute_reply.started":"2025-09-26T14:25:47.941899Z","shell.execute_reply":"2025-09-26T14:25:48.318714Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"all_words = []\nall_tags = []\nfor i, row in tqdm(train_df_raw.iterrows()):\n    words_sample = []\n    entities_sample = []\n    for ent in row['annotation']:\n        word = row['sample'][ent[0]:ent[1]]\n        words_sample.append(word)\n        entities_sample.append(ent[2])\n    all_words.append(words_sample)\n    all_tags.append(entities_sample)\n    # print(words_sample, entities_sample)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38zKIXDInmC_","outputId":"86b3c56b-e254-4997-cddd-532395265fb4","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:48.766148Z","iopub.execute_input":"2025-09-26T14:25:48.766730Z","iopub.status.idle":"2025-09-26T14:25:49.820112Z","shell.execute_reply.started":"2025-09-26T14:25:48.766705Z","shell.execute_reply":"2025-09-26T14:25:49.819383Z"}},"outputs":[{"name":"stderr","text":"27552it [00:01, 26338.87it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"assert len(all_words) == len(all_tags), 'different lengths'","metadata":{"id":"TkGRmYpSpzpZ","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:50.397595Z","iopub.execute_input":"2025-09-26T14:25:50.397819Z","iopub.status.idle":"2025-09-26T14:25:50.401525Z","shell.execute_reply.started":"2025-09-26T14:25:50.397802Z","shell.execute_reply":"2025-09-26T14:25:50.400965Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"lbls_in_dataset = [\n 'O',\n 'B-BRAND',\n 'B-PERCENT',\n 'B-TYPE',\n 'B-VOLUME',\n 'I-BRAND',\n 'I-PERCENT',\n 'I-TYPE',\n 'I-VOLUME']\nlabel2id = {v:i for i, v in enumerate(lbls_in_dataset)}\nid2label = {i:v for i, v in enumerate(lbls_in_dataset)}","metadata":{"id":"RCNtZyfzsmbq","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:50.613902Z","iopub.execute_input":"2025-09-26T14:25:50.614365Z","iopub.status.idle":"2025-09-26T14:25:50.617926Z","shell.execute_reply.started":"2025-09-26T14:25:50.614348Z","shell.execute_reply":"2025-09-26T14:25:50.617205Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"features=Features(\n    {\n        \"id\": Value(dtype='int32', id=None),\n        \"tokens\": Sequence(feature=Value(dtype='string', id=None)),\n        \"ner_tags\": Sequence(feature=ClassLabel(num_classes=len(lbls_in_dataset), names=list(lbls_in_dataset)), id=None)\n    }\n)","metadata":{"id":"N16RjsvYrPvW","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:52.221601Z","iopub.execute_input":"2025-09-26T14:25:52.222205Z","iopub.status.idle":"2025-09-26T14:25:52.226439Z","shell.execute_reply.started":"2025-09-26T14:25:52.222177Z","shell.execute_reply":"2025-09-26T14:25:52.225515Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"ds = Dataset.from_dict({\"id\": list(range(len(all_words))),\n                        \"tokens\": all_words,\n                        \"ner_tags\": all_tags},\n                       features=features)","metadata":{"id":"NtF5L20Nt7oo","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:25:52.480553Z","iopub.execute_input":"2025-09-26T14:25:52.480755Z","iopub.status.idle":"2025-09-26T14:25:52.766629Z","shell.execute_reply.started":"2025-09-26T14:25:52.480740Z","shell.execute_reply":"2025-09-26T14:25:52.765639Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"ds_splitted = ds.train_test_split(\n    test_size=0.25, shuffle=True, seed=42,\n    # stratify_by_column='ner_tags'\n)","metadata":{"id":"UvKyy7ZAs-Oa"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Counter([x for l in ds['ner_tags'] for x in l])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XK4Panavxkxj","outputId":"63860067-3615-4cef-80e4-f11219157ed6","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:24:01.849246Z","iopub.execute_input":"2025-09-26T10:24:01.849541Z","iopub.status.idle":"2025-09-26T10:24:01.925664Z","shell.execute_reply.started":"2025-09-26T10:24:01.849518Z","shell.execute_reply":"2025-09-26T10:24:01.925014Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"Counter({0: 5407,\n         1: 7252,\n         3: 24845,\n         5: 490,\n         7: 4703,\n         2: 180,\n         4: 207,\n         8: 163,\n         6: 15})"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"Counter([x for l in ds_splitted['test']['ner_tags'] for x in l])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQJREIqBvNx_","outputId":"a09d7e3f-3dc1-4def-8c48-934e119871b1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({3: 6129, 1: 1774, 7: 1133, 0: 1358, 5: 122, 2: 9, 4: 18, 8: 8, 6: 2})"]},"metadata":{},"execution_count":14}],"execution_count":null},{"cell_type":"markdown","source":"## Загрузка модели","metadata":{"id":"BA0HcZtox2QD"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/rut5_large_ft_colab_2509/pytorch/default/1/ruT5_large_250925',\n                                          use_fast=True,\n                                          add_prefix_space=True)\n\nmodel = AutoModelForTokenClassification.from_pretrained('/kaggle/input/rut5_large_ft_colab_2509/pytorch/default/1/ruT5_large_250925',\n                                                        num_labels=len(lbls_in_dataset),\n                                                        id2label=id2label,\n                                                        label2id=label2id).to(\"cuda\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["a5b0e7638d6d4c4ca0996d7b020e59d6","c9d7f068b3b1456b94729031bf250e94","3a24111dace7456a9e37fbb60d04c38b","35d94b59d14549b5b9d86553a348e420","7479e69dcd50435e884e334cc0cf38ee","174e223ef4a945579f9eb7f4ae0e93e4","d79c62114fd142029255e0db1d52ed9a","f96b1b42a7e44816852f51b36e39dd09","833566aa83484331b5c11dfdb7f21ee9","52e1f4410c4f4c3d8cc06c0157a03af7","74ccad71321d41cea860aaefec83502d","5beb6f270e544ad3b5f2b9edd2605a5b","fc0a360c3f2a4aaeb70b1885824fa0e1","f908bd7798154697a9ff049ae264d9fb","4d28a06aede948a294baaf885731bb09","64d1aa0086b84b87bc7a92e0c58eef1c","76a07ea51a1d4e8d80962661675ea36e","bafb54e447c648a5882908f01813707d","f74a6c9f08894d0d9d1aefa18dc2ac17","7de1fa7fcd614b418298905d6ec4f797","d75f429947524e71ab02959544ba3c61","854e9b2131e945f69fea27cbcea4c144","bd16b83691fd460e8cd07c0dd51a8aa2","6a3cb4e7e20d461db1e9a97415ed9e7c","b3bc82a5af874c27a57e117569aba3f0","1a2717f60ca9484abbafb785df3faa46","0ea90c0f92c4414c8f93a554a74cfab1","9287aa5abe4746128c2eeb1a4547a61a","a1cdb359996b4942ad1b416fbd747e97","c2efdb87c7844176991e0906f1f183dc","ae82b099a4f143e38d82feb76211b8fb","43fdcf9676544621b741aa7ad751f621","dc799160c3714d9087f92c71c5bf79e2"]},"id":"UC9EFn5p22gO","outputId":"38141ac6-91bd-4ddd-b88d-98b751e02579","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:02:12.235006Z","iopub.execute_input":"2025-09-26T13:02:12.235444Z","iopub.status.idle":"2025-09-26T13:02:24.703848Z","shell.execute_reply.started":"2025-09-26T13:02:12.235423Z","shell.execute_reply":"2025-09-26T13:02:24.703107Z"}},"outputs":[{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"s = '''\nсироп топинамбура\n'''\nr = tokenizer(s)\n[tokenizer.decode(x) for x in r.input_ids][:5]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBYSXH1hx6ZS","outputId":"278b6768-1b75-473b-a8ca-9ccf3f53967b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['сироп', 'то', 'пина', 'м', 'бур']"]},"metadata":{},"execution_count":17}],"execution_count":null},{"cell_type":"markdown","source":"## Токенизация и подготовка","metadata":{"id":"0ur88vOsyenk"}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples, tokenizer):\n    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n\n    labels = []\n    for i, label in enumerate(examples['ner_tags']):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_index = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            else:\n                label_ids.append(label[word_idx])\n        labels.append(label_ids)\n\n    tokenized_inputs['labels'] = labels\n    return tokenized_inputs","metadata":{"id":"pLXEC3IAyTQ0","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:29:27.801409Z","iopub.execute_input":"2025-09-26T14:29:27.801680Z","iopub.status.idle":"2025-09-26T14:29:27.806777Z","shell.execute_reply.started":"2025-09-26T14:29:27.801660Z","shell.execute_reply":"2025-09-26T14:29:27.805999Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"tokenized_ds_train = ds_splitted['train'].map(tokenize_and_align_labels,\n                                              batched=True,\n                                              fn_kwargs={'tokenizer': tokenizer})","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["219043a57bd8424c8a3ccf0c1a54115c","50329a055e564b429c0c2c3e81f08272","7fd98312f8c94562b016b924a38efc80","31657f0e1130493d9faa5511f648fa53","4bc7b0ae0c4b4685bbcc941601390f78","d05042af89454f91ba8bdf52d85f11fd","57c2910ccdfb47eeb7c1645e82778573","f4ebf79726ab40eaa1ac7fc99e0a38ce","d1f3799d8ade4c3981ddce11e76a0fcd","0366d2f2ee7c4c4b9621c3afd5e75f23","4dbe44cb63504cc6b81778510201e2e3"]},"id":"_ARzDgYBy2Ih","outputId":"7b2d53b0-9805-4855-be50-23a146ab19d2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/20438 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"219043a57bd8424c8a3ccf0c1a54115c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"execution_count":null},{"cell_type":"code","source":"tokenized_ds_test = ds_splitted['test'].map(tokenize_and_align_labels,\n                                              batched=True,\n                                              fn_kwargs={'tokenizer': tokenizer})","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d76a2f0f26d7457cb26bebde30ed5e0e","c117ffca9f6b4146b305b558f7939847","dc094b00dec74afb802ee7d6df12c1be","374bb6ddc4a64823b2cfdd327864a953","b32f39249a974519ba3b1fd956c53276","e1e6420c5c4b409980a2a951dad44dd8","87b888ce920d454dad4945fa26643fe8","259f9f4db413414a823a1a3f241a98a7","5e340cbd6da544828ce8609fb500945d","56093491341a4bf39bfe7b09fdd41e86","a25d768bb6cd45b18999ede839a8428c"]},"id":"sKYNr2E6y5oO","outputId":"2c4f7688-e86f-461d-8958-8456ae21ff40"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6813 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76a2f0f26d7457cb26bebde30ed5e0e"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Обучение","metadata":{"id":"9uwZDDAX0DbU"}},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f\"Using device: {device}\")\n\nprint(\"Compiling model for faster training...\")\ntorch.set_float32_matmul_precision('high')\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqxjKTvAzVlL","outputId":"5c6abf53-21d3-4984-ef8e-7a882c4d4656"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n","Compiling model for faster training...\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForTokenClassification(\n","  (transformer): T5EncoderModel(\n","    (shared): Embedding(32128, 1024)\n","    (encoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 1024)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","                (relative_attention_bias): Embedding(32, 16)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseActDense(\n","                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): ReLU()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1-23): 23 x T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseActDense(\n","                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): ReLU()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n",")"]},"metadata":{},"execution_count":21}],"execution_count":null},{"cell_type":"code","source":"# функция метрики\ndef compute_metrics_custom(p):\n    labels_list = list(id2label.values())\n    predictions, labels = p\n    if not os.path.exists('/content/test/p_trainer.pkl'):\n        os.makedirs('/content/test', exist_ok=True)\n        with open('/content/test/p_trainer.pkl', 'wb') as f:\n            pickle.dump(p, f)\n    predictions = np.argmax(predictions, axis=2)\n\n\n    true_predictions = [\n        [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n    report_dict = classification_report(true_labels, true_predictions, digits=4, output_dict=True)\n    report = classification_report(true_labels, true_predictions, digits=4)\n    macro_f1 = report_dict[\"macro avg\"][\"f1-score\"]\n    print(\"=== seqeval classification_report ===\")\n    print(report)\n    CLASS_REPORT_PATH = '/content/logs/last_classification_report.txt'\n    try:\n        with open(CLASS_REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n            f.write(report)\n    except Exception as e:\n        print(f\"Warning: failed to write classification report to {CLASS_REPORT_PATH}: {e}\")\n\n    return {\n        \"f1_macro\": macro_f1,\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"id":"vYjFZW220FJS"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"id":"MMcW2Zs4EvvD"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna.logging\noptuna.logging.set_verbosity(optuna.logging.INFO)\n\nbest_f1 = 0\n\nGDRIVE_DIR = '/content/drive/MyDrive/Hackatons/X5_ner_2025/ruT5_large_250925'\n\ndef printer(s):\n    print('*'*150, end='\\n\\n')\n    print(s, end='\\n\\n')\n    print('*'*150, end='\\n\\n')","metadata":{"id":"0cdPNPNR3MqG"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop_cb = EarlyStoppingCallback(early_stopping_patience=2)","metadata":{"id":"mP5VlP__32Oi"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial: optuna.Trial, model=model):\n    global best_f1\n    model = model\n    model_name = 'ruT5_large_250925_optuna_v1'\n    trial_check_dir = f\"./checkpoints_trial\"\n\n    os.makedirs(trial_check_dir, exist_ok=True)\n    args = TrainingArguments(\n        # f\"{model_name}-finetuned-ner\",\n        output_dir=trial_check_dir,\n        overwrite_output_dir=True,\n        eval_strategy = \"epoch\",\n        torch_compile=True,\n        # 64\\\n        per_device_train_batch_size=256,\n        per_device_eval_batch_size=256,\n        learning_rate=trial.suggest_loguniform('learning_rate', low=1e-5, high=5e-4),\n        weight_decay=trial.suggest_loguniform('weight_decay', 1e-4, 0.05),\n        num_train_epochs=trial.suggest_int('num_train_epochs', low = 3, high = 10),\n        seed=42,\n        data_seed=24,\n        gradient_accumulation_steps=2,\n        warmup_ratio=0.1,\n        report_to=None,\n        logging_dir=\"./logs\",\n        logging_steps=1,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_f1_macro\",\n        # greater_is_better=False,\n        save_total_limit=1,\n        save_strategy=\"epoch\",  # Changed to match evaluation_strategy\n    )\n\n    # early_stopping = EarlyStoppingCallback(\n    #     early_stopping_patience=1,  # Stop if F1 decreases for 1 consecutive epoch\n    #     early_stopping_threshold=0.001\n    # )\n\n    trainer = Trainer(\n        model,\n        args,\n        train_dataset=tokenized_ds_train,\n        eval_dataset=tokenized_ds_test,\n        # train_dataset=small_dataset_train,\n        # eval_dataset=small_dataset_test,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics_custom,\n        tokenizer=tokenizer,\n        callbacks=[early_stop_cb],\n    )\n\n    trainer.train()\n\n    # Evaluate and save best model globally\n    eval_metrics = trainer.evaluate()\n    current_f1 = eval_metrics[\"eval_f1_macro\"]\n\n    if current_f1 > best_f1:\n        best_f1 = current_f1\n        trainer.save_model(\"./best_model\")\n        trainer.save_model(GDRIVE_DIR)\n        printer(f\"New best model saved with F1: {best_f1:.4f}\")\n    return current_f1","metadata":{"id":"o-sZkAfk3OMb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"study = optuna.create_study(study_name='test_optuna', direction='maximize')\nstudy.optimize(func=objective, n_trials=5)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gM3DK3Sj3XQA","outputId":"daddce65-aa09-4fb5-b986-9dd1e03b5745"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-09-25 15:47:56,064] A new study created in memory with name: test_optuna\n","/tmp/ipython-input-992928850.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate=trial.suggest_loguniform('learning_rate', low=1e-5, high=5e-4),\n","/tmp/ipython-input-992928850.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay=trial.suggest_loguniform('weight_decay', 1e-4, 0.05),\n","The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","/tmp/ipython-input-992928850.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","W0925 15:48:54.194000 16270 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [360/360 29:08, Epoch 9/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1 Macro</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.742300</td>\n","      <td>0.537095</td>\n","      <td>0.400311</td>\n","      <td>0.803884</td>\n","      <td>0.892531</td>\n","      <td>0.845891</td>\n","      <td>0.843418</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.362400</td>\n","      <td>0.358328</td>\n","      <td>0.450653</td>\n","      <td>0.905844</td>\n","      <td>0.943039</td>\n","      <td>0.924067</td>\n","      <td>0.915001</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.158600</td>\n","      <td>0.302577</td>\n","      <td>0.579675</td>\n","      <td>0.930021</td>\n","      <td>0.954029</td>\n","      <td>0.941872</td>\n","      <td>0.930194</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.158400</td>\n","      <td>0.325737</td>\n","      <td>0.720133</td>\n","      <td>0.916179</td>\n","      <td>0.951784</td>\n","      <td>0.933642</td>\n","      <td>0.924071</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.033900</td>\n","      <td>0.308182</td>\n","      <td>0.823673</td>\n","      <td>0.938384</td>\n","      <td>0.958659</td>\n","      <td>0.948413</td>\n","      <td>0.937526</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.041600</td>\n","      <td>0.379980</td>\n","      <td>0.770415</td>\n","      <td>0.939387</td>\n","      <td>0.954543</td>\n","      <td>0.946905</td>\n","      <td>0.936732</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.036000</td>\n","      <td>0.425532</td>\n","      <td>0.874428</td>\n","      <td>0.938848</td>\n","      <td>0.960670</td>\n","      <td>0.949634</td>\n","      <td>0.938206</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.014800</td>\n","      <td>0.478993</td>\n","      <td>0.876659</td>\n","      <td>0.943126</td>\n","      <td>0.959313</td>\n","      <td>0.951151</td>\n","      <td>0.938773</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.004200</td>\n","      <td>0.514241</td>\n","      <td>0.876177</td>\n","      <td>0.942816</td>\n","      <td>0.958425</td>\n","      <td>0.950557</td>\n","      <td>0.938093</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.6379    0.7954    0.7080      5043\n","     PERCENT     0.0000    0.0000    0.0000        14\n","        TYPE     0.8637    0.9250    0.8933     16297\n","      VOLUME     0.0000    0.0000    0.0000        29\n","\n","   micro avg     0.8039    0.8925    0.8459     21383\n","   macro avg     0.3754    0.4301    0.4003     21383\n","weighted avg     0.8087    0.8925    0.8478     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8601    0.8547    0.8574      5043\n","     PERCENT     0.0000    0.0000    0.0000        14\n","        TYPE     0.9191    0.9729    0.9452     16297\n","      VOLUME     0.0000    0.0000    0.0000        29\n","\n","   micro avg     0.9058    0.9430    0.9241     21383\n","   macro avg     0.4448    0.4569    0.4507     21383\n","weighted avg     0.9034    0.9430    0.9226     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8873    0.9011    0.8941      5043\n","     PERCENT     1.0000    0.0714    0.1333        14\n","        TYPE     0.9439    0.9723    0.9579     16297\n","      VOLUME     0.3600    0.3103    0.3333        29\n","\n","   micro avg     0.9300    0.9540    0.9419     21383\n","   macro avg     0.7978    0.5638    0.5797     21383\n","weighted avg     0.9298    0.9540    0.9415     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8240    0.9365    0.8767      5043\n","     PERCENT     0.8000    0.2857    0.4211        14\n","        TYPE     0.9487    0.9577    0.9532     16297\n","      VOLUME     0.6800    0.5862    0.6296        29\n","\n","   micro avg     0.9162    0.9518    0.9336     21383\n","   macro avg     0.8132    0.6915    0.7201     21383\n","weighted avg     0.9188    0.9518    0.9344     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9110    0.9009    0.9059      5043\n","     PERCENT     0.7500    0.6429    0.6923        14\n","        TYPE     0.9467    0.9774    0.9618     16297\n","      VOLUME     0.9000    0.6207    0.7347        29\n","\n","   micro avg     0.9384    0.9587    0.9484     21383\n","   macro avg     0.8769    0.7855    0.8237     21383\n","weighted avg     0.9381    0.9587    0.9481     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8843    0.9231    0.9033      5043\n","     PERCENT     0.7273    0.5714    0.6400        14\n","        TYPE     0.9576    0.9654    0.9615     16297\n","      VOLUME     0.6522    0.5172    0.5769        29\n","\n","   micro avg     0.9394    0.9545    0.9469     21383\n","   macro avg     0.8053    0.7443    0.7704     21383\n","weighted avg     0.9397    0.9545    0.9470     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9047    0.9110    0.9078      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9493    0.9765    0.9627     16297\n","      VOLUME     0.8929    0.8621    0.8772        29\n","\n","   micro avg     0.9388    0.9607    0.9496     21383\n","   macro avg     0.9117    0.8481    0.8744     21383\n","weighted avg     0.9387    0.9607    0.9495     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9096    0.9139    0.9118      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9535    0.9737    0.9635     16297\n","      VOLUME     0.8667    0.8966    0.8814        29\n","\n","   micro avg     0.9431    0.9593    0.9512     21383\n","   macro avg     0.9074    0.8568    0.8767     21383\n","weighted avg     0.9430    0.9593    0.9511     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9070    0.9131    0.9101      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9539    0.9728    0.9633     16297\n","      VOLUME     0.8667    0.8966    0.8814        29\n","\n","   micro avg     0.9428    0.9584    0.9506     21383\n","   macro avg     0.9069    0.8563    0.8762     21383\n","weighted avg     0.9427    0.9584    0.9505     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight'].\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:13]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9096    0.9139    0.9118      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9535    0.9737    0.9635     16297\n","      VOLUME     0.8667    0.8966    0.8814        29\n","\n","   micro avg     0.9431    0.9593    0.9512     21383\n","   macro avg     0.9074    0.8568    0.8767     21383\n","weighted avg     0.9430    0.9593    0.9511     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-09-25 16:21:06,317] Trial 0 finished with value: 0.8766589668718043 and parameters: {'learning_rate': 0.0004683284028374025, 'weight_decay': 0.0020733902422178014, 'num_train_epochs': 9}. Best is trial 0 with value: 0.8766589668718043.\n","/tmp/ipython-input-992928850.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate=trial.suggest_loguniform('learning_rate', low=1e-5, high=5e-4),\n","/tmp/ipython-input-992928850.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay=trial.suggest_loguniform('weight_decay', 1e-4, 0.05),\n","The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"output_type":"stream","name":"stdout","text":["******************************************************************************************************************************************************\n","\n","New best model saved with F1: 0.8767\n","\n","******************************************************************************************************************************************************\n","\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-992928850.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [280/280 20:31, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1 Macro</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.002900</td>\n","      <td>0.546093</td>\n","      <td>0.872007</td>\n","      <td>0.943423</td>\n","      <td>0.959968</td>\n","      <td>0.951624</td>\n","      <td>0.939189</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.000900</td>\n","      <td>0.623692</td>\n","      <td>0.854504</td>\n","      <td>0.941767</td>\n","      <td>0.960529</td>\n","      <td>0.951056</td>\n","      <td>0.939076</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.000100</td>\n","      <td>0.644883</td>\n","      <td>0.872071</td>\n","      <td>0.942940</td>\n","      <td>0.960623</td>\n","      <td>0.951699</td>\n","      <td>0.939453</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.001000</td>\n","      <td>0.610403</td>\n","      <td>0.871778</td>\n","      <td>0.944058</td>\n","      <td>0.958893</td>\n","      <td>0.951418</td>\n","      <td>0.939302</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.000200</td>\n","      <td>0.615621</td>\n","      <td>0.872327</td>\n","      <td>0.943050</td>\n","      <td>0.961044</td>\n","      <td>0.951962</td>\n","      <td>0.940134</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.000200</td>\n","      <td>0.625413</td>\n","      <td>0.872305</td>\n","      <td>0.942818</td>\n","      <td>0.960763</td>\n","      <td>0.951706</td>\n","      <td>0.939869</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.000100</td>\n","      <td>0.628055</td>\n","      <td>0.872243</td>\n","      <td>0.942769</td>\n","      <td>0.960670</td>\n","      <td>0.951635</td>\n","      <td>0.939907</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9143    0.9096    0.9119      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9523    0.9760    0.9640     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9434    0.9600    0.9516     21383\n","   macro avg     0.9072    0.8476    0.8720     21383\n","weighted avg     0.9432    0.9600    0.9515     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9089    0.9137    0.9113      5043\n","     PERCENT     0.8889    0.5714    0.6957        14\n","        TYPE     0.9520    0.9755    0.9636     16297\n","      VOLUME     0.8333    0.8621    0.8475        29\n","\n","   micro avg     0.9418    0.9605    0.9511     21383\n","   macro avg     0.8958    0.8307    0.8545     21383\n","weighted avg     0.9416    0.9605    0.9509     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9100    0.9141    0.9121      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9531    0.9755    0.9642     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9429    0.9606    0.9517     21383\n","   macro avg     0.9063    0.8486    0.8721     21383\n","weighted avg     0.9428    0.9606    0.9516     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9113    0.9106    0.9109      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9541    0.9743    0.9641     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9441    0.9589    0.9514     21383\n","   macro avg     0.9069    0.8474    0.8718     21383\n","weighted avg     0.9439    0.9589    0.9513     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9085    0.9175    0.9130      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9538    0.9750    0.9643     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9430    0.9610    0.9520     21383\n","   macro avg     0.9061    0.8494    0.8723     21383\n","weighted avg     0.9429    0.9610    0.9519     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9109    0.9159    0.9134      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9527    0.9751    0.9638     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9428    0.9608    0.9517     21383\n","   macro avg     0.9064    0.8490    0.8723     21383\n","weighted avg     0.9427    0.9608    0.9516     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9100    0.9163    0.9132      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9529    0.9748    0.9638     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9428    0.9607    0.9516     21383\n","   macro avg     0.9062    0.8490    0.8722     21383\n","weighted avg     0.9426    0.9607    0.9515     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight'].\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:14]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-09-25 16:41:59,096] Trial 1 finished with value: 0.8723269404322582 and parameters: {'learning_rate': 1.6956919779303677e-05, 'weight_decay': 0.0004587134033578368, 'num_train_epochs': 7}. Best is trial 0 with value: 0.8766589668718043.\n","/tmp/ipython-input-992928850.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate=trial.suggest_loguniform('learning_rate', low=1e-5, high=5e-4),\n","/tmp/ipython-input-992928850.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay=trial.suggest_loguniform('weight_decay', 1e-4, 0.05),\n","The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9085    0.9175    0.9130      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9538    0.9750    0.9643     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9430    0.9610    0.9520     21383\n","   macro avg     0.9061    0.8494    0.8723     21383\n","weighted avg     0.9429    0.9610    0.9519     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-992928850.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/360 14:00 < 11:19, 0.24 it/s, Epoch 5/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1 Macro</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>1.073410</td>\n","      <td>0.871447</td>\n","      <td>0.943406</td>\n","      <td>0.958098</td>\n","      <td>0.950695</td>\n","      <td>0.938017</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.001500</td>\n","      <td>0.843991</td>\n","      <td>0.870619</td>\n","      <td>0.942651</td>\n","      <td>0.957022</td>\n","      <td>0.949782</td>\n","      <td>0.937866</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.000200</td>\n","      <td>1.071172</td>\n","      <td>0.892632</td>\n","      <td>0.940048</td>\n","      <td>0.962821</td>\n","      <td>0.951298</td>\n","      <td>0.939151</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>1.034390</td>\n","      <td>0.883332</td>\n","      <td>0.941954</td>\n","      <td>0.960015</td>\n","      <td>0.950899</td>\n","      <td>0.939000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.000600</td>\n","      <td>0.740452</td>\n","      <td>0.887223</td>\n","      <td>0.941660</td>\n","      <td>0.959407</td>\n","      <td>0.950451</td>\n","      <td>0.939265</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9087    0.9120    0.9103      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9541    0.9728    0.9634     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9434    0.9581    0.9507     21383\n","   macro avg     0.9062    0.8474    0.8714     21383\n","weighted avg     0.9433    0.9581    0.9506     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9020    0.9177    0.9098      5043\n","     PERCENT     1.0000    0.6429    0.7826        14\n","        TYPE     0.9554    0.9697    0.9625     16297\n","      VOLUME     0.8276    0.8276    0.8276        29\n","\n","   micro avg     0.9427    0.9570    0.9498     21383\n","   macro avg     0.9212    0.8395    0.8706     21383\n","weighted avg     0.9427    0.9570    0.9498     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9099    0.9129    0.9114      5043\n","     PERCENT     1.0000    0.7143    0.8333        14\n","        TYPE     0.9492    0.9786    0.9637     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9400    0.9628    0.9513     21383\n","   macro avg     0.9303    0.8670    0.8926     21383\n","weighted avg     0.9399    0.9628    0.9512     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9045    0.9149    0.9097      5043\n","     PERCENT     1.0000    0.6429    0.7826        14\n","        TYPE     0.9535    0.9744    0.9638     16297\n","      VOLUME     0.8929    0.8621    0.8772        29\n","\n","   micro avg     0.9420    0.9600    0.9509     21383\n","   macro avg     0.9377    0.8486    0.8833     21383\n","weighted avg     0.9419    0.9600    0.9508     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8981    0.9227    0.9102      5043\n","     PERCENT     1.0000    0.7143    0.8333        14\n","        TYPE     0.9554    0.9712    0.9632     16297\n","      VOLUME     0.8571    0.8276    0.8421        29\n","\n","   micro avg     0.9417    0.9594    0.9505     21383\n","   macro avg     0.9277    0.8589    0.8872     21383\n","weighted avg     0.9418    0.9594    0.9505     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight'].\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:14]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9099    0.9129    0.9114      5043\n","     PERCENT     1.0000    0.7143    0.8333        14\n","        TYPE     0.9492    0.9786    0.9637     16297\n","      VOLUME     0.8621    0.8621    0.8621        29\n","\n","   micro avg     0.9400    0.9628    0.9513     21383\n","   macro avg     0.9303    0.8670    0.8926     21383\n","weighted avg     0.9399    0.9628    0.9512     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-09-25 16:56:43,952] Trial 2 finished with value: 0.8926324166140165 and parameters: {'learning_rate': 6.44944805049113e-05, 'weight_decay': 0.004066034568680406, 'num_train_epochs': 9}. Best is trial 2 with value: 0.8926324166140165.\n","/tmp/ipython-input-992928850.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate=trial.suggest_loguniform('learning_rate', low=1e-5, high=5e-4),\n","/tmp/ipython-input-992928850.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay=trial.suggest_loguniform('weight_decay', 1e-4, 0.05),\n","The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"output_type":"stream","name":"stdout","text":["******************************************************************************************************************************************************\n","\n","New best model saved with F1: 0.8926\n","\n","******************************************************************************************************************************************************\n","\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-992928850.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='120' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [120/360 08:45 < 17:48, 0.22 it/s, Epoch 3/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1 Macro</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.137000</td>\n","      <td>0.558386</td>\n","      <td>0.858002</td>\n","      <td>0.936880</td>\n","      <td>0.950288</td>\n","      <td>0.943536</td>\n","      <td>0.931932</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.031900</td>\n","      <td>0.395097</td>\n","      <td>0.795494</td>\n","      <td>0.938484</td>\n","      <td>0.951036</td>\n","      <td>0.944718</td>\n","      <td>0.931970</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.008900</td>\n","      <td>0.435523</td>\n","      <td>0.804443</td>\n","      <td>0.941481</td>\n","      <td>0.952532</td>\n","      <td>0.946974</td>\n","      <td>0.934805</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8983    0.8937    0.8960      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9487    0.9683    0.9584     16297\n","      VOLUME     0.8276    0.8276    0.8276        29\n","\n","   micro avg     0.9369    0.9503    0.9435     21383\n","   macro avg     0.8937    0.8331    0.8580     21383\n","weighted avg     0.9366    0.9503    0.9434     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8909    0.9100    0.9003      5043\n","     PERCENT     0.8333    0.7143    0.7692        14\n","        TYPE     0.9537    0.9648    0.9592     16297\n","      VOLUME     0.7222    0.4483    0.5532        29\n","\n","   micro avg     0.9385    0.9510    0.9447     21383\n","   macro avg     0.8500    0.7593    0.7955     21383\n","weighted avg     0.9385    0.9510    0.9447     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9095    0.8949    0.9021      5043\n","     PERCENT     0.7333    0.7857    0.7586        14\n","        TYPE     0.9514    0.9713    0.9613     16297\n","      VOLUME     0.7778    0.4828    0.5957        29\n","\n","   micro avg     0.9415    0.9525    0.9470     21383\n","   macro avg     0.8430    0.7837    0.8044     21383\n","weighted avg     0.9411    0.9525    0.9467     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight'].\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:14]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-09-25 17:05:50,476] Trial 3 finished with value: 0.8580016656503588 and parameters: {'learning_rate': 0.00048392903640124505, 'weight_decay': 0.0038169848188184135, 'num_train_epochs': 9}. Best is trial 2 with value: 0.8926324166140165.\n","/tmp/ipython-input-992928850.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate=trial.suggest_loguniform('learning_rate', low=1e-5, high=5e-4),\n","/tmp/ipython-input-992928850.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay=trial.suggest_loguniform('weight_decay', 1e-4, 0.05),\n","The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.8983    0.8937    0.8960      5043\n","     PERCENT     0.9000    0.6429    0.7500        14\n","        TYPE     0.9487    0.9683    0.9584     16297\n","      VOLUME     0.8276    0.8276    0.8276        29\n","\n","   micro avg     0.9369    0.9503    0.9435     21383\n","   macro avg     0.8937    0.8331    0.8580     21383\n","weighted avg     0.9366    0.9503    0.9434     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-992928850.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [120/120 08:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1 Macro</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.009600</td>\n","      <td>0.497267</td>\n","      <td>0.858961</td>\n","      <td>0.939611</td>\n","      <td>0.957583</td>\n","      <td>0.948512</td>\n","      <td>0.936846</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.001700</td>\n","      <td>0.623256</td>\n","      <td>0.883508</td>\n","      <td>0.939863</td>\n","      <td>0.956741</td>\n","      <td>0.948227</td>\n","      <td>0.936392</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.000200</td>\n","      <td>0.633704</td>\n","      <td>0.879540</td>\n","      <td>0.940540</td>\n","      <td>0.958706</td>\n","      <td>0.949536</td>\n","      <td>0.937866</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9097    0.9014    0.9056      5043\n","     PERCENT     1.0000    0.6429    0.7826        14\n","        TYPE     0.9487    0.9756    0.9619     16297\n","      VOLUME     0.8148    0.7586    0.7857        29\n","\n","   micro avg     0.9396    0.9576    0.9485     21383\n","   macro avg     0.9183    0.8196    0.8590     21383\n","weighted avg     0.9394    0.9576    0.9483     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9054    0.9032    0.9043      5043\n","     PERCENT     1.0000    0.6429    0.7826        14\n","        TYPE     0.9504    0.9736    0.9619     16297\n","      VOLUME     0.8438    0.9310    0.8852        29\n","\n","   micro avg     0.9399    0.9567    0.9482     21383\n","   macro avg     0.9249    0.8627    0.8835     21383\n","weighted avg     0.9397    0.9567    0.9481     21383\n","\n","=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9074    0.9040    0.9057      5043\n","     PERCENT     1.0000    0.6429    0.7826        14\n","        TYPE     0.9506    0.9760    0.9632     16297\n","      VOLUME     0.8387    0.8966    0.8667        29\n","\n","   micro avg     0.9405    0.9587    0.9495     21383\n","   macro avg     0.9242    0.8549    0.8795     21383\n","weighted avg     0.9403    0.9587    0.9494     21383\n","\n"]},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight'].\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:14]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-09-25 17:14:40,644] Trial 4 finished with value: 0.8835080653340189 and parameters: {'learning_rate': 0.00012973534241957156, 'weight_decay': 0.0006306410098490446, 'num_train_epochs': 3}. Best is trial 2 with value: 0.8926324166140165.\n"]},{"output_type":"stream","name":"stdout","text":["=== seqeval classification_report ===\n","              precision    recall  f1-score   support\n","\n","       BRAND     0.9054    0.9032    0.9043      5043\n","     PERCENT     1.0000    0.6429    0.7826        14\n","        TYPE     0.9504    0.9736    0.9619     16297\n","      VOLUME     0.8438    0.9310    0.8852        29\n","\n","   micro avg     0.9399    0.9567    0.9482     21383\n","   macro avg     0.9249    0.8627    0.8835     21383\n","weighted avg     0.9397    0.9567    0.9481     21383\n","\n"]}],"execution_count":null},{"cell_type":"code","source":"best_trial = study.best_trial\nprinter(f\"Final best F1: {best_trial.value}\")\nprinter(f\"Final params: {best_trial.params}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFMzaJHRFzka","outputId":"cb94c27c-0ccf-4eb1-e259-e3599810e9e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["******************************************************************************************************************************************************\n","\n","Final best F1: 0.8926324166140165\n","\n","******************************************************************************************************************************************************\n","\n","******************************************************************************************************************************************************\n","\n","Final params: {'learning_rate': 6.44944805049113e-05, 'weight_decay': 0.004066034568680406, 'num_train_epochs': 9}\n","\n","******************************************************************************************************************************************************\n","\n"]}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"2zVG89pKFzhz"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## тест","metadata":{"id":"5Zr5wuGcCKj-"}},{"cell_type":"code","source":"df_test = pd.read_csv('submission.csv', sep=';', usecols=['sample'])","metadata":{"id":"7vMnAC-kGaWC"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_path = '/content/drive/MyDrive/Hackatons/X5_ner_2025/ruT5_large_250925'\nfinal_tokenizer = AutoTokenizer.from_pretrained(best_model_path, use_fast=True, add_prefix_space=True)\nfinal_model = AutoModelForTokenClassification.from_pretrained(best_model_path)\n","metadata":{"id":"d-lZjXh2CLlY"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_model.to('cuda')","metadata":{"id":"Km6LgmUEdlaL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"16cac88a-b60d-4f0c-ec4d-d31e9aa215c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForTokenClassification(\n","  (transformer): T5EncoderModel(\n","    (shared): Embedding(32128, 1024)\n","    (encoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 1024)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","                (relative_attention_bias): Embedding(32, 16)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseActDense(\n","                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): ReLU()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1-23): 23 x T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseActDense(\n","                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): ReLU()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n",")"]},"metadata":{},"execution_count":35}],"execution_count":null},{"cell_type":"code","source":"token_classifier = pipeline(\n    \"token-classification\", model=final_model, aggregation_strategy=\"first\", tokenizer=final_tokenizer\n)\nfor s in samples:\n    print(f'sample: {s}')\n    res = token_classifier(s)\n    for i, r in enumerate(res):\n        # print('Entity: '+ r['entity_group'] + '   Word: ' + r['word'])\n        print('Entity: '+ r['entity_group'] + '   Word: ' + r['word'] + '. Probs:  ' + str(round(r['score'], 4)))\n    print('#'*40)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"GhB6AHvk446v","outputId":"68d19b89-5595-4d00-e8a2-f595c33f76af"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'samples' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-926685419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"token-classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'sample: {s}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"]}],"execution_count":null},{"cell_type":"code","source":"s = 'очиститель для унитаза'\nres = token_classifier(s)\nfor i, r in enumerate(res):\n    # print('Entity: '+ r['entity_group'] + '   Word: ' + r['word'])\n    print('Entity: '+ r['entity_group'] + '   Word: ' + r['word'] + '. Probs:  ' + str(round(r['score'], 4)))\nprint(res)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0gOiZCtH7ya","outputId":"2c9727b7-1033-4149-cc37-f92a10719607"},"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: TYPE   Word: очиститель. Probs:  0.9998\n","[{'entity_group': 'TYPE', 'score': np.float32(0.9997584), 'word': 'очиститель', 'start': 0, 'end': 10}]\n"]}],"execution_count":null},{"cell_type":"code","source":"lbls_in_dataset = [\n 'O',\n 'B-BRAND',\n 'B-PERCENT',\n 'B-TYPE',\n 'B-VOLUME',\n 'I-BRAND',\n 'I-PERCENT',\n 'I-TYPE',\n 'I-VOLUME']\nlabel2id = {v:i for i, v in enumerate(lbls_in_dataset)}\nid2label = {i:v for i, v in enumerate(lbls_in_dataset)}","metadata":{"id":"PiJyCZtGJY6T"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport re\n\ndef predict_all_entities(text: str, model, tokenizer, id2label, device=None, debug=False):\n    \"\"\"\n    Word-level inference with original character spans (start_idx, end_idx, ENTITY).\n    Returns a list of tuples for each word (including 'O').\n    \"\"\"\n\n    model.eval()\n    if device is None:\n        device = next(model.parameters()).device\n\n    # --- find words and their char spans in original text ---\n    words = []\n    spans = []\n    for match in re.finditer(r\"\\S+\", text):\n        words.append(match.group())\n        spans.append(match.span())  # (start_idx, end_idx)\n\n    # encode with word-level info\n    enc = tokenizer(\n        words,\n        is_split_into_words=True,\n        return_tensors=\"pt\",\n        truncation=True\n    )\n\n    input_ids = enc[\"input_ids\"].to(device)\n    attention_mask = enc[\"attention_mask\"].to(device)\n    word_ids = enc.word_ids(batch_index=0)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits[0]               # (seq_len, num_labels)\n        probs = F.softmax(logits, dim=-1)        # (seq_len, num_labels)\n    # print()\n    # print(probs)\n    results = []\n    prev_word_idx = None\n    # print(word_ids)\n    for token_idx, word_idx in enumerate(word_ids):\n        if debug:\n            print(token_idx, word_idx, logits[token_idx])\n        if word_idx is None:\n            prev_word_idx = None\n            continue\n\n        # only take first subtoken per word\n        if word_idx != prev_word_idx:\n            label_id = int(torch.argmax(logits[token_idx]).cpu().numpy())\n            label = id2label[label_id]\n\n            start_idx, end_idx = spans[word_idx]\n            results.append((start_idx, end_idx, label))\n\n        prev_word_idx = word_idx\n\n    return results\n\n\n# -------------------------\n# Example usage\n# -------------------------\ns = \"сыр натура сливочный\"\n\n# Example id2label (replace with your mapping)\n# id2label = {0: \"O\", 1: \"B-TYPE\", 2: \"I-TYPE\", ...}\n\nres = predict_all_entities(s, trained_model, tokenizer, id2label)\nprint(res)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"K3XfLW2HILpe","outputId":"cd2e872b-90af-4e54-dd90-bc2560e56421","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:45:07.058964Z","iopub.execute_input":"2025-09-26T14:45:07.059338Z","iopub.status.idle":"2025-09-26T14:45:07.130463Z","shell.execute_reply.started":"2025-09-26T14:45:07.059316Z","shell.execute_reply":"2025-09-26T14:45:07.129880Z"}},"outputs":[{"name":"stdout","text":"[(0, 3, 'B-TYPE'), (4, 10, 'B-BRAND'), (11, 20, 'I-BRAND')]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"annotations = []\nfor s in tqdm(df_test['sample'].tolist()):\n    r = predict_all_entities(s, final_model, final_tokenizer, id2label)\n    annotations.append(r)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiNM_xC_Kr2z","outputId":"bc43b4cd-6c32-4004-b46f-cf4a097f4c8e"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5000/5000 [01:59<00:00, 41.73it/s]\n"]}],"execution_count":null},{"cell_type":"code","source":"df_test['annotation'] = annotations","metadata":{"id":"kXvAYjGsK53U"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.sample(20)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"lJnBzEdQO-UA","outputId":"d86136c7-7a3a-4a2e-a7d8-bf13f1128e27"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                sample                           annotation\n","1501            куркум                     [(0, 6, B-TYPE)]\n","2586            вялены                     [(0, 6, B-TYPE)]\n","2653         exponetto                    [(0, 9, B-BRAND)]\n","1055  моцарелла шарики   [(0, 9, B-TYPE), (10, 16, I-TYPE)]\n","705       галеты petra   [(0, 6, B-TYPE), (7, 12, B-BRAND)]\n","106            ванилик                     [(0, 7, B-TYPE)]\n","589           нектар j    [(0, 6, B-TYPE), (7, 8, B-BRAND)]\n","2468               тнк                          [(0, 3, O)]\n","2413       рыбный фарш    [(0, 6, B-TYPE), (7, 11, I-TYPE)]\n","1600  сгущенные молочн   [(0, 9, B-TYPE), (10, 16, I-TYPE)]\n","2464          вереники                     [(0, 8, B-TYPE)]\n","228              пончо                     [(0, 5, B-TYPE)]\n","915              ол йс         [(0, 2, B-BRAND), (3, 5, O)]\n","794            йогуртп                     [(0, 7, B-TYPE)]\n","3021          пнмидоры                     [(0, 8, B-TYPE)]\n","3543           семечко                     [(0, 7, B-TYPE)]\n","1073     разрыхлительн                    [(0, 13, B-TYPE)]\n","3351            слифки                     [(0, 6, B-TYPE)]\n","1744  доя мытья посуды  [(0, 3, O), (4, 9, O), (10, 16, O)]\n","1084      круассан лим   [(0, 8, B-TYPE), (9, 12, B-BRAND)]"],"text/html":["\n","  <div id=\"df-ad773860-a83a-4851-8079-d74780bad119\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sample</th>\n","      <th>annotation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1501</th>\n","      <td>куркум</td>\n","      <td>[(0, 6, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>2586</th>\n","      <td>вялены</td>\n","      <td>[(0, 6, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>2653</th>\n","      <td>exponetto</td>\n","      <td>[(0, 9, B-BRAND)]</td>\n","    </tr>\n","    <tr>\n","      <th>1055</th>\n","      <td>моцарелла шарики</td>\n","      <td>[(0, 9, B-TYPE), (10, 16, I-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>705</th>\n","      <td>галеты petra</td>\n","      <td>[(0, 6, B-TYPE), (7, 12, B-BRAND)]</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>ванилик</td>\n","      <td>[(0, 7, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>589</th>\n","      <td>нектар j</td>\n","      <td>[(0, 6, B-TYPE), (7, 8, B-BRAND)]</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>тнк</td>\n","      <td>[(0, 3, O)]</td>\n","    </tr>\n","    <tr>\n","      <th>2413</th>\n","      <td>рыбный фарш</td>\n","      <td>[(0, 6, B-TYPE), (7, 11, I-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>1600</th>\n","      <td>сгущенные молочн</td>\n","      <td>[(0, 9, B-TYPE), (10, 16, I-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>2464</th>\n","      <td>вереники</td>\n","      <td>[(0, 8, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>пончо</td>\n","      <td>[(0, 5, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>915</th>\n","      <td>ол йс</td>\n","      <td>[(0, 2, B-BRAND), (3, 5, O)]</td>\n","    </tr>\n","    <tr>\n","      <th>794</th>\n","      <td>йогуртп</td>\n","      <td>[(0, 7, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>3021</th>\n","      <td>пнмидоры</td>\n","      <td>[(0, 8, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>3543</th>\n","      <td>семечко</td>\n","      <td>[(0, 7, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>1073</th>\n","      <td>разрыхлительн</td>\n","      <td>[(0, 13, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>3351</th>\n","      <td>слифки</td>\n","      <td>[(0, 6, B-TYPE)]</td>\n","    </tr>\n","    <tr>\n","      <th>1744</th>\n","      <td>доя мытья посуды</td>\n","      <td>[(0, 3, O), (4, 9, O), (10, 16, O)]</td>\n","    </tr>\n","    <tr>\n","      <th>1084</th>\n","      <td>круассан лим</td>\n","      <td>[(0, 8, B-TYPE), (9, 12, B-BRAND)]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad773860-a83a-4851-8079-d74780bad119')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ad773860-a83a-4851-8079-d74780bad119 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ad773860-a83a-4851-8079-d74780bad119');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-047a93af-a29c-4008-848f-bb771052a08e\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-047a93af-a29c-4008-848f-bb771052a08e')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-047a93af-a29c-4008-848f-bb771052a08e button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df_test\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"sample\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\u043a\\u0443\\u0440\\u043a\\u0443\\u043c\",\n          \"\\u0441\\u043b\\u0438\\u0444\\u043a\\u0438\",\n          \"\\u0441\\u0435\\u043c\\u0435\\u0447\\u043a\\u043e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":40}],"execution_count":null},{"cell_type":"code","source":"df_test.to_csv('submission_ruT5_large_250925.csv', index=False, sep=';')","metadata":{"id":"jNY15xLhO_ma"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## k-fold","metadata":{"id":"A34migI_LXaj"}},{"cell_type":"code","source":"n_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# Create a list to hold each fold (train/val split)\nfolds = []\n\nfor train_idx, val_idx in kf.split(ds):\n    train_split = ds.select(train_idx)\n    val_split = ds.select(val_idx)\n    folds.append(DatasetDict({\"train\": train_split, \"validation\": val_split}))","metadata":{"id":"eIejBGeQLSVE","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:22:06.573140Z","iopub.execute_input":"2025-09-26T11:22:06.573890Z","iopub.status.idle":"2025-09-26T11:22:06.628558Z","shell.execute_reply.started":"2025-09-26T11:22:06.573865Z","shell.execute_reply":"2025-09-26T11:22:06.627950Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained('ai-forever/ruT5-large',\n#                                           use_fast=True,\n#                                           add_prefix_space=True)\n\n# model = AutoModelForTokenClassification.from_pretrained('ai-forever/ruT5-large',\n#                                                         num_labels=len(lbls_in_dataset),\n#                                                         id2label=id2label,\n#                                                         label2id=label2id).to(\"cuda\")","metadata":{"id":"xJCbZ29WLSQZ","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:26:18.237348Z","iopub.execute_input":"2025-09-26T09:26:18.238159Z","iopub.status.idle":"2025-09-26T09:26:18.242160Z","shell.execute_reply.started":"2025-09-26T09:26:18.238124Z","shell.execute_reply":"2025-09-26T09:26:18.241232Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# lbls_in_dataset = [\n#  'O',\n#  'B-BRAND',\n#  'B-PERCENT',\n#  'B-TYPE',\n#  'B-VOLUME',\n#  'I-BRAND',\n#  'I-PERCENT',\n#  'I-TYPE',\n#  'I-VOLUME']\n# label2id = {v:i for i, v in enumerate(lbls_in_dataset)}\n# id2label = {i:v for i, v in enumerate(lbls_in_dataset)}","metadata":{"id":"PUvFXgqeMZmb","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:26:23.297201Z","iopub.execute_input":"2025-09-26T09:26:23.297502Z","iopub.status.idle":"2025-09-26T09:26:23.301220Z","shell.execute_reply.started":"2025-09-26T09:26:23.297467Z","shell.execute_reply":"2025-09-26T09:26:23.300355Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"id":"lzrIpRnUMdjN","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:22:12.930942Z","iopub.execute_input":"2025-09-26T11:22:12.931725Z","iopub.status.idle":"2025-09-26T11:22:12.935048Z","shell.execute_reply.started":"2025-09-26T11:22:12.931703Z","shell.execute_reply":"2025-09-26T11:22:12.934391Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"df_all_valid_docs = pd.DataFrame()\n\nfor fold in folds:\n    print(f\"Start training for fold {fold}\")\n    ds_train = fold['train'].map(tokenize_and_align_labels,\n                                              batched=True,\n                                              fn_kwargs={'tokenizer': tokenizer})\n    ds_validation = fold['validation'].map(tokenize_and_align_labels,\n                                              batched=True,\n                                              fn_kwargs={'tokenizer': tokenizer})\n    training_args = TrainingArguments(\n        eval_strategy=\"no\",  # No evaluation during training\n        torch_compile=True,\n        per_device_train_batch_size=256,\n        learning_rate=6.44944805049113e-05,          # fixed value (was suggested by Optuna before)\n        weight_decay=0.004066034568680406,\n        num_train_epochs=3,          # fixed\n        seed=42,\n        data_seed=24,\n        gradient_accumulation_steps=2,\n        warmup_ratio=0.1,\n        report_to=None,\n        logging_dir=\"./logs\",\n        logging_steps=20,\n        )\n\n    # Initialize Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=ds_train,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n\n    )\n\n    # Start training\n    print(\"Starting training without evaluation...\")\n    trainer.train()\n    trained_model = trainer.model\n\n    # Optional: Save final model\n    print(f\"Training completed for fold {fold}\")\n\n    df_valid = ds_validation.to_pandas()\n    predicted_ner_tags = []\n    for doc in df_valid['tokens'].tolist():\n        predicted_doc_ner = predict_all_entities(doc[0], trained_model, tokenizer, id2label)\n        predicted_ner_tags.append(predicted_doc_ner)\n    df_valid['predicted_ner_tags'] = predicted_ner_tags\n\n    if df_all_valid_docs.empty:\n        df_all_valid_docs = df_valid\n    else:\n        df_all_valid_docs = pd.concat([df_all_valid_docs, df_valid])","metadata":{"id":"HZD3Go7CLSNn","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:14:57.979597Z","iopub.execute_input":"2025-09-26T10:14:57.979872Z"}},"outputs":[{"name":"stdout","text":"Start training for fold DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c78c0b4cbd4561b398759d29a743fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa703b433d9046d5b81e6cfa776eeb37"}},"metadata":{}},{"name":"stderr","text":"The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"Starting training without evaluation...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3955522077.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:13, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training completed for fold DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n})\nStart training for fold DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a61202bf14e433a93a0333b12e3fad5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4675d15aeeb48cdb0ec1c2ce4c5704c"}},"metadata":{}},{"name":"stderr","text":"The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"Starting training without evaluation...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3955522077.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:12, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training completed for fold DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n})\nStart training for fold DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 100\n    })\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e833c67bb0a4f4a87319063a7f093b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3e751efe5b14eabb391778c1c224df6"}},"metadata":{}},{"name":"stderr","text":"The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"Starting training without evaluation...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3955522077.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"doc[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:14:48.037216Z","iopub.execute_input":"2025-09-26T10:14:48.037490Z","iopub.status.idle":"2025-09-26T10:14:48.042412Z","shell.execute_reply.started":"2025-09-26T10:14:48.037472Z","shell.execute_reply":"2025-09-26T10:14:48.041544Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'abon'"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"df_all_valid_docs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:11:58.486328Z","iopub.execute_input":"2025-09-26T10:11:58.486620Z","iopub.status.idle":"2025-09-26T10:11:58.518843Z","shell.execute_reply.started":"2025-09-26T10:11:58.486600Z","shell.execute_reply":"2025-09-26T10:11:58.518096Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"         id            tokens ner_tags  \\\n0         3            [abon]      [0]   \n1         6  [abtoys, игрушк]   [1, 3]   \n2        17          [active]      [1]   \n3        29           [agata]      [1]   \n4        30     [agnesi, пше]   [1, 3]   \n...     ...               ...      ...   \n5445  27232             [яыц]      [3]   \n5446  27233            [яыца]      [3]   \n5447  27240        [№1, газе]   [1, 3]   \n5448  27247    [№1, кофейник]   [1, 3]   \n5449  27249          [№1, са]   [1, 3]   \n\n                                         input_ids  \\\n0                               [8, 4877, 1146, 2]   \n1     [8, 4877, 2769, 448, 125, 5112, 319, 189, 2]   \n2                               [8, 4128, 2496, 2]   \n3                              [8, 6084, 12625, 2]   \n4               [8, 6084, 16805, 633, 454, 682, 2]   \n...                                            ...   \n5445                              [35, 19, 557, 2]   \n5446                              [35, 19, 518, 2]   \n5447                       [545, 471, 3762, 13, 2]   \n5448                     [545, 471, 18465, 588, 2]   \n5449                          [545, 471, 11, 7, 2]   \n\n                   attention_mask                          labels  \\\n0                    [1, 1, 1, 1]                 [0, 0, 0, -100]   \n1     [1, 1, 1, 1, 1, 1, 1, 1, 1]  [1, 1, 1, 1, 1, 3, 3, 3, -100]   \n2                    [1, 1, 1, 1]                 [1, 1, 1, -100]   \n3                    [1, 1, 1, 1]                 [1, 1, 1, -100]   \n4           [1, 1, 1, 1, 1, 1, 1]        [1, 1, 1, 1, 3, 3, -100]   \n...                           ...                             ...   \n5445                 [1, 1, 1, 1]                 [3, 3, 3, -100]   \n5446                 [1, 1, 1, 1]                 [3, 3, 3, -100]   \n5447              [1, 1, 1, 1, 1]              [1, 1, 3, 3, -100]   \n5448              [1, 1, 1, 1, 1]              [1, 1, 3, 3, -100]   \n5449              [1, 1, 1, 1, 1]              [1, 1, 3, 3, -100]   \n\n                                     predicted_ner_tags  \n0     [(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...  \n1     [(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...  \n2     [(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...  \n3     [(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...  \n4     [(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...  \n...                                                 ...  \n5445  [(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...  \n5446  [(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...  \n5447  [(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...  \n5448  [(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...  \n5449  [(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...  \n\n[27251 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tokens</th>\n      <th>ner_tags</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n      <th>predicted_ner_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>[abon]</td>\n      <td>[0]</td>\n      <td>[8, 4877, 1146, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[0, 0, 0, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>[abtoys, игрушк]</td>\n      <td>[1, 3]</td>\n      <td>[8, 4877, 2769, 448, 125, 5112, 319, 189, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[1, 1, 1, 1, 1, 3, 3, 3, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17</td>\n      <td>[active]</td>\n      <td>[1]</td>\n      <td>[8, 4128, 2496, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[1, 1, 1, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29</td>\n      <td>[agata]</td>\n      <td>[1]</td>\n      <td>[8, 6084, 12625, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[1, 1, 1, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>[agnesi, пше]</td>\n      <td>[1, 3]</td>\n      <td>[8, 6084, 16805, 633, 454, 682, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[1, 1, 1, 1, 3, 3, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, I-TYPE), (11, 20, I-T...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5445</th>\n      <td>27232</td>\n      <td>[яыц]</td>\n      <td>[3]</td>\n      <td>[35, 19, 557, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[3, 3, 3, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...</td>\n    </tr>\n    <tr>\n      <th>5446</th>\n      <td>27233</td>\n      <td>[яыца]</td>\n      <td>[3]</td>\n      <td>[35, 19, 518, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[3, 3, 3, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...</td>\n    </tr>\n    <tr>\n      <th>5447</th>\n      <td>27240</td>\n      <td>[№1, газе]</td>\n      <td>[1, 3]</td>\n      <td>[545, 471, 3762, 13, 2]</td>\n      <td>[1, 1, 1, 1, 1]</td>\n      <td>[1, 1, 3, 3, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...</td>\n    </tr>\n    <tr>\n      <th>5448</th>\n      <td>27247</td>\n      <td>[№1, кофейник]</td>\n      <td>[1, 3]</td>\n      <td>[545, 471, 18465, 588, 2]</td>\n      <td>[1, 1, 1, 1, 1]</td>\n      <td>[1, 1, 3, 3, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...</td>\n    </tr>\n    <tr>\n      <th>5449</th>\n      <td>27249</td>\n      <td>[№1, са]</td>\n      <td>[1, 3]</td>\n      <td>[545, 471, 11, 7, 2]</td>\n      <td>[1, 1, 1, 1, 1]</td>\n      <td>[1, 1, 3, 3, -100]</td>\n      <td>[(0, 3, B-TYPE), (4, 10, B-BRAND), (11, 20, I-...</td>\n    </tr>\n  </tbody>\n</table>\n<p>27251 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df_all_valid_docs.iloc[-1]['predicted_ner_tags']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:12:48.842684Z","iopub.execute_input":"2025-09-26T10:12:48.842951Z","iopub.status.idle":"2025-09-26T10:12:48.848452Z","shell.execute_reply.started":"2025-09-26T10:12:48.842933Z","shell.execute_reply":"2025-09-26T10:12:48.847869Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 20, 'I-TYPE')]"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## где ошибка в трейне","metadata":{"id":"PBNShRveLSnW"}},{"cell_type":"code","source":"df_valid_final[df_valid_final.annotation.astype(str) != df_valid_final.ann.astype(str)].to_csv('comparison_valid.csv', index=False)","metadata":{"id":"I4FzZLmhh-ek"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folds[0]","metadata":{"id":"ytXg6f7xiaOK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"370ae089-5651-4d3e-c8a7-b815c2333643"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'tokens', 'ner_tags'],\n","        num_rows: 21800\n","    })\n","    validation: Dataset({\n","        features: ['id', 'tokens', 'ner_tags'],\n","        num_rows: 5451\n","    })\n","})"]},"metadata":{},"execution_count":21}],"execution_count":null},{"cell_type":"code","source":"dd = pd.DataFrame()\ndd.empty","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZSjgCa0NkKY","outputId":"c93044c0-7d81-4222-8641-97ae78411c76"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":23}],"execution_count":null},{"cell_type":"markdown","source":"## итоговая тренировка","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('ai-forever/ruT5-large',\n                                          use_fast=True,\n                                          add_prefix_space=True)\n\nmodel = AutoModelForTokenClassification.from_pretrained('ai-forever/ruT5-large',\n                                                        num_labels=len(lbls_in_dataset),\n                                                        id2label=id2label,\n                                                        label2id=label2id).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:27:12.344394Z","iopub.execute_input":"2025-09-26T14:27:12.344656Z","iopub.status.idle":"2025-09-26T14:27:36.643808Z","shell.execute_reply.started":"2025-09-26T14:27:12.344637Z","shell.execute_reply":"2025-09-26T14:27:36.638093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16f6c06ad0d4db2b2fd6a50316be173"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"102f5e5f9e39459a9738d18bbfd3586a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92434367fa4a4c969eaca784e453f955"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nYou set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21fe6946b6b44c4b9c425019ea258281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"777569cf1cd84bfda024e10eb05255f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b65bb299c224e539db0e0a9cbc29783"}},"metadata":{}},{"name":"stderr","text":"Some weights of T5ForTokenClassification were not initialized from the model checkpoint at ai-forever/ruT5-large and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:28:17.917006Z","iopub.execute_input":"2025-09-26T14:28:17.917305Z","iopub.status.idle":"2025-09-26T14:28:17.920953Z","shell.execute_reply.started":"2025-09-26T14:28:17.917285Z","shell.execute_reply":"2025-09-26T14:28:17.920122Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\nds_train = ds.map(tokenize_and_align_labels,\n                                          batched=True,\n                                          fn_kwargs={'tokenizer': tokenizer})\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"no\",  # No evaluation during training\n    torch_compile=True,\n    per_device_train_batch_size=256,\n    learning_rate=0.00019727099511884864,          # fixed value (was suggested by Optuna before)\n    weight_decay=0.000514766062249604,\n    num_train_epochs=8,          # fixed\n    seed=42,\n    data_seed=24,\n    gradient_accumulation_steps=2,\n    warmup_ratio=0.1,\n    report_to=None,\n    logging_dir=\"./logs\",\n    logging_steps=20,\n    )\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_train,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n\n)\n\n# Start training\nprint(\"Starting training without evaluation...\")\ntrainer.train()\ntrained_model = trainer.model\n\n\n","metadata":{"id":"wwzsP16fPLTe","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:29:48.534125Z","iopub.execute_input":"2025-09-26T14:29:48.534482Z","iopub.status.idle":"2025-09-26T14:44:48.731049Z","shell.execute_reply.started":"2025-09-26T14:29:48.534460Z","shell.execute_reply":"2025-09-26T14:44:48.730228Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27552 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f70ac929824a13a590c70d2e69b5bc"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nThe speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/tmp/ipykernel_36/3766512879.py:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"name":"stdout","text":"Starting training without evaluation...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [216/216 14:53, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>3.110800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.822800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.526000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.352200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.252800</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.188400</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.154100</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.125000</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.089600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"ds_train.select(range(5)).to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:44:49.025512Z","iopub.execute_input":"2025-09-26T14:44:49.026363Z","iopub.status.idle":"2025-09-26T14:44:49.060771Z","shell.execute_reply.started":"2025-09-26T14:44:49.026326Z","shell.execute_reply":"2025-09-26T14:44:49.060064Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   id    tokens ner_tags                  input_ids   attention_mask  \\\n0   0      [aa]      [0]              [351, 500, 2]        [1, 1, 1]   \n1   1    [aala]      [0]         [351, 700, 500, 2]     [1, 1, 1, 1]   \n2   2  [aarcca]      [0]  [351, 1228, 679, 4701, 2]  [1, 1, 1, 1, 1]   \n3   3    [abon]      [0]         [8, 4877, 1146, 2]     [1, 1, 1, 1]   \n4   4    [abso]      [1]        [8, 4877, 12364, 2]     [1, 1, 1, 1]   \n\n               labels  \n0        [0, 0, -100]  \n1     [0, 0, 0, -100]  \n2  [0, 0, 0, 0, -100]  \n3     [0, 0, 0, -100]  \n4     [1, 1, 1, -100]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tokens</th>\n      <th>ner_tags</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[aa]</td>\n      <td>[0]</td>\n      <td>[351, 500, 2]</td>\n      <td>[1, 1, 1]</td>\n      <td>[0, 0, -100]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[aala]</td>\n      <td>[0]</td>\n      <td>[351, 700, 500, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[0, 0, 0, -100]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[aarcca]</td>\n      <td>[0]</td>\n      <td>[351, 1228, 679, 4701, 2]</td>\n      <td>[1, 1, 1, 1, 1]</td>\n      <td>[0, 0, 0, 0, -100]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[abon]</td>\n      <td>[0]</td>\n      <td>[8, 4877, 1146, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[0, 0, 0, -100]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[abso]</td>\n      <td>[1]</td>\n      <td>[8, 4877, 12364, 2]</td>\n      <td>[1, 1, 1, 1]</td>\n      <td>[1, 1, 1, -100]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df_validation = pd.read_csv(\"/kaggle/input/submission/submission.csv\", sep=\";\", usecols=['sample'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:47:15.235847Z","iopub.execute_input":"2025-09-26T14:47:15.236354Z","iopub.status.idle":"2025-09-26T14:47:15.249004Z","shell.execute_reply.started":"2025-09-26T14:47:15.236332Z","shell.execute_reply":"2025-09-26T14:47:15.248300Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"predicted_ner_tags = []\nfor doc in tqdm(df_validation['sample'].tolist()):\n    predicted_doc_ner = predict_all_entities(doc, trained_model, tokenizer, id2label)\n    predicted_ner_tags.append(predicted_doc_ner)\ndf_validation['annotation'] = predicted_ner_tags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:47:16.124421Z","iopub.execute_input":"2025-09-26T14:47:16.125007Z","iopub.status.idle":"2025-09-26T14:48:55.723330Z","shell.execute_reply.started":"2025-09-26T14:47:16.124986Z","shell.execute_reply":"2025-09-26T14:48:55.722699Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 5000/5000 [01:39<00:00, 50.21it/s]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"trained_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:51:53.599236Z","iopub.execute_input":"2025-09-26T14:51:53.599933Z","iopub.status.idle":"2025-09-26T14:51:53.606013Z","shell.execute_reply.started":"2025-09-26T14:51:53.599911Z","shell.execute_reply":"2025-09-26T14:51:53.605409Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"T5ForTokenClassification(\n  (transformer): T5EncoderModel(\n    (shared): Embedding(32128, 1024)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 1024)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=1024, out_features=1024, bias=False)\n                (k): Linear(in_features=1024, out_features=1024, bias=False)\n                (v): Linear(in_features=1024, out_features=1024, bias=False)\n                (o): Linear(in_features=1024, out_features=1024, bias=False)\n                (relative_attention_bias): Embedding(32, 16)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-23): 23 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=1024, out_features=1024, bias=False)\n                (k): Linear(in_features=1024, out_features=1024, bias=False)\n                (v): Linear(in_features=1024, out_features=1024, bias=False)\n                (o): Linear(in_features=1024, out_features=1024, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (dropout): Dropout(p=0.0, inplace=False)\n  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"df_validation.sample(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:57.229225Z","iopub.execute_input":"2025-09-26T14:48:57.229732Z","iopub.status.idle":"2025-09-26T14:48:57.245937Z","shell.execute_reply.started":"2025-09-26T14:48:57.229714Z","shell.execute_reply":"2025-09-26T14:48:57.245201Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                sample                           annotation\n1501            куркум                     [(0, 6, B-TYPE)]\n2586            вялены                     [(0, 6, B-TYPE)]\n2653         exponetto                    [(0, 9, B-BRAND)]\n1055  моцарелла шарики   [(0, 9, B-TYPE), (10, 16, I-TYPE)]\n705       галеты petra   [(0, 6, B-TYPE), (7, 12, B-BRAND)]\n106            ванилик                     [(0, 7, B-TYPE)]\n589           нектар j    [(0, 6, B-TYPE), (7, 8, B-BRAND)]\n2468               тнк                          [(0, 3, O)]\n2413       рыбный фарш    [(0, 6, B-TYPE), (7, 11, I-TYPE)]\n1600  сгущенные молочн   [(0, 9, B-TYPE), (10, 16, I-TYPE)]\n2464          вереники                     [(0, 8, B-TYPE)]\n228              пончо                     [(0, 5, B-TYPE)]\n915              ол йс               [(0, 2, O), (3, 5, O)]\n794            йогуртп                     [(0, 7, B-TYPE)]\n3021          пнмидоры                     [(0, 8, B-TYPE)]\n3543           семечко                     [(0, 7, B-TYPE)]\n1073     разрыхлительн                    [(0, 13, B-TYPE)]\n3351            слифки                     [(0, 6, B-TYPE)]\n1744  доя мытья посуды  [(0, 3, O), (4, 9, O), (10, 16, O)]\n1084      круассан лим   [(0, 8, B-TYPE), (9, 12, B-BRAND)]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>annotation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1501</th>\n      <td>куркум</td>\n      <td>[(0, 6, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>2586</th>\n      <td>вялены</td>\n      <td>[(0, 6, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>2653</th>\n      <td>exponetto</td>\n      <td>[(0, 9, B-BRAND)]</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>моцарелла шарики</td>\n      <td>[(0, 9, B-TYPE), (10, 16, I-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>705</th>\n      <td>галеты petra</td>\n      <td>[(0, 6, B-TYPE), (7, 12, B-BRAND)]</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>ванилик</td>\n      <td>[(0, 7, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>нектар j</td>\n      <td>[(0, 6, B-TYPE), (7, 8, B-BRAND)]</td>\n    </tr>\n    <tr>\n      <th>2468</th>\n      <td>тнк</td>\n      <td>[(0, 3, O)]</td>\n    </tr>\n    <tr>\n      <th>2413</th>\n      <td>рыбный фарш</td>\n      <td>[(0, 6, B-TYPE), (7, 11, I-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>1600</th>\n      <td>сгущенные молочн</td>\n      <td>[(0, 9, B-TYPE), (10, 16, I-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>2464</th>\n      <td>вереники</td>\n      <td>[(0, 8, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>228</th>\n      <td>пончо</td>\n      <td>[(0, 5, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>ол йс</td>\n      <td>[(0, 2, O), (3, 5, O)]</td>\n    </tr>\n    <tr>\n      <th>794</th>\n      <td>йогуртп</td>\n      <td>[(0, 7, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>3021</th>\n      <td>пнмидоры</td>\n      <td>[(0, 8, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>3543</th>\n      <td>семечко</td>\n      <td>[(0, 7, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>1073</th>\n      <td>разрыхлительн</td>\n      <td>[(0, 13, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>3351</th>\n      <td>слифки</td>\n      <td>[(0, 6, B-TYPE)]</td>\n    </tr>\n    <tr>\n      <th>1744</th>\n      <td>доя мытья посуды</td>\n      <td>[(0, 3, O), (4, 9, O), (10, 16, O)]</td>\n    </tr>\n    <tr>\n      <th>1084</th>\n      <td>круассан лим</td>\n      <td>[(0, 8, B-TYPE), (9, 12, B-BRAND)]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"df_validation.to_csv('submission_ruT5_large_ft_augmented_new_hyperparams_260925.csv', index=False, sep=';')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:49:13.556850Z","iopub.execute_input":"2025-09-26T14:49:13.557555Z","iopub.status.idle":"2025-09-26T14:49:13.580388Z","shell.execute_reply.started":"2025-09-26T14:49:13.557531Z","shell.execute_reply":"2025-09-26T14:49:13.579667Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"predict_all_entities(\"garner ructi\", trained_model, tokenizer, id2label, debug=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:45:16.688508Z","iopub.execute_input":"2025-09-26T14:45:16.689115Z","iopub.status.idle":"2025-09-26T14:45:16.796599Z","shell.execute_reply.started":"2025-09-26T14:45:16.689093Z","shell.execute_reply":"2025-09-26T14:45:16.795957Z"}},"outputs":[{"name":"stdout","text":"0 0 tensor([ 6.5906, 10.1643, -2.2721,  3.4366, -4.5278,  2.5592, -2.8466, -6.9580,\n        -3.9529], device='cuda:0')\n1 0 tensor([ 7.7309, 10.9714, -3.8946,  3.1987, -4.7314,  3.2854, -1.5130, -5.1659,\n        -4.1112], device='cuda:0')\n2 0 tensor([ 7.2921, 10.1729, -5.3683,  2.7412, -4.5518,  4.3491, -3.4186, -4.6163,\n        -5.3117], device='cuda:0')\n3 1 tensor([ 5.6538,  3.8720, -0.9463,  3.5795, -3.4112,  5.8417, -3.4994, -3.0971,\n        -2.3954], device='cuda:0')\n4 1 tensor([ 6.2706,  6.4004, -1.8007,  6.0896, -2.7667,  3.7546, -2.8255, -1.3013,\n        -5.2245], device='cuda:0')\n5 1 tensor([ 6.1525,  4.2112, -3.2930,  6.1238, -4.6684,  3.9089, -2.6030, -0.5535,\n        -2.8735], device='cuda:0')\n6 1 tensor([ 6.2605,  5.1263, -3.0759,  4.7641, -2.6424,  4.7713, -2.8157, -2.3314,\n        -4.1695], device='cuda:0')\n7 None tensor([ 1.7911, -0.1701,  0.5656, -0.5731,  1.6106, -0.8561,  2.0464,  2.4553,\n         1.5692], device='cuda:0')\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[(0, 6, 'B-BRAND'), (7, 12, 'I-BRAND')]"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"id2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:18:11.560728Z","iopub.execute_input":"2025-09-26T13:18:11.561004Z","iopub.status.idle":"2025-09-26T13:18:11.565846Z","shell.execute_reply.started":"2025-09-26T13:18:11.560984Z","shell.execute_reply":"2025-09-26T13:18:11.565089Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{0: 'O',\n 1: 'B-BRAND',\n 2: 'B-PERCENT',\n 3: 'B-TYPE',\n 4: 'B-VOLUME',\n 5: 'I-BRAND',\n 6: 'I-PERCENT',\n 7: 'I-TYPE',\n 8: 'I-VOLUME'}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"tokenizer.tokenize(\" garner ructi\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:18:15.784375Z","iopub.execute_input":"2025-09-26T13:18:15.784632Z","iopub.status.idle":"2025-09-26T13:18:15.789648Z","shell.execute_reply.started":"2025-09-26T13:18:15.784613Z","shell.execute_reply":"2025-09-26T13:18:15.789081Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"['▁', 'gar', 'ner', '▁', 'ru', 'c', 'ti']"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# молоко 1,5 % -- не находит процент\n# стейк говядина --  проверить усреднение\n# сок 2 литра яблочный -- не находит volume ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:55:52.952042Z","iopub.execute_input":"2025-09-26T10:55:52.952738Z","iopub.status.idle":"2025-09-26T10:55:52.956844Z","shell.execute_reply.started":"2025-09-26T10:55:52.952706Z","shell.execute_reply":"2025-09-26T10:55:52.955806Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"predict_all_entities(\"schwartau со\", trained_model, tokenizer, id2label, debug=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:20:55.738312Z","iopub.execute_input":"2025-09-26T13:20:55.739171Z","iopub.status.idle":"2025-09-26T13:20:55.786446Z","shell.execute_reply.started":"2025-09-26T13:20:55.739138Z","shell.execute_reply":"2025-09-26T13:20:55.785714Z"}},"outputs":[{"name":"stdout","text":"0 0 tensor([ 2.4230e+00,  1.3040e+01, -6.8861e-03,  9.9319e-01, -1.6785e+00,\n        -1.4810e+00, -8.7815e-01, -2.5692e-01, -1.3998e+00], device='cuda:0')\n1 0 tensor([ 2.2394, 12.3609,  0.4930,  1.3229, -1.7823, -0.0829, -1.3356, -0.2234,\n        -0.8064], device='cuda:0')\n2 0 tensor([ 2.6557e+00,  1.3508e+01,  1.0873e-02,  1.7207e+00, -2.1920e+00,\n         4.2342e-01, -7.9274e-01, -9.1873e-02, -1.4111e+00], device='cuda:0')\n3 0 tensor([ 2.6026, 13.6531, -0.9042,  1.6521, -2.1215,  0.8590, -0.8216, -1.2197,\n        -0.8692], device='cuda:0')\n4 0 tensor([ 3.3646, 14.1260,  0.9424,  1.7963, -0.5018,  1.6216, -1.6133, -2.3228,\n        -1.5213], device='cuda:0')\n5 1 tensor([ 6.6762, -1.6012, -2.8019, 11.6132, -3.1620,  1.1287, -1.9783,  0.8047,\n        -2.5529], device='cuda:0')\n6 None tensor([ 6.3755, -2.4741, -3.1129, 14.5177, -3.3633, -0.2019, -3.0747,  1.3072,\n        -4.7479], device='cuda:0')\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[(0, 9, 'B-BRAND'), (10, 12, 'B-TYPE')]"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"tokenizer.tokenize(\"крем jundo\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T13:19:50.266235Z","iopub.execute_input":"2025-09-26T13:19:50.266535Z","iopub.status.idle":"2025-09-26T13:19:50.271674Z","shell.execute_reply.started":"2025-09-26T13:19:50.266508Z","shell.execute_reply":"2025-09-26T13:19:50.271150Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"['▁крем', '▁j', 'und', 'o']"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer2 = AutoTokenizer.from_pretrained('ai-forever/ruT5-large',\n                                          use_fast=True,\n                                          add_prefix_space=True)\n\nmodel2 = AutoModel.from_pretrained('ai-forever/ruT5-large').to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:53:47.663258Z","iopub.execute_input":"2025-09-26T14:53:47.663911Z","iopub.status.idle":"2025-09-26T14:53:55.954353Z","shell.execute_reply.started":"2025-09-26T14:53:47.663890Z","shell.execute_reply":"2025-09-26T14:53:55.953505Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"model2.encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:54:41.455613Z","iopub.execute_input":"2025-09-26T14:54:41.456355Z","iopub.status.idle":"2025-09-26T14:54:41.462526Z","shell.execute_reply.started":"2025-09-26T14:54:41.456329Z","shell.execute_reply":"2025-09-26T14:54:41.461765Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"T5Stack(\n  (embed_tokens): Embedding(32128, 1024)\n  (block): ModuleList(\n    (0): T5Block(\n      (layer): ModuleList(\n        (0): T5LayerSelfAttention(\n          (SelfAttention): T5Attention(\n            (q): Linear(in_features=1024, out_features=1024, bias=False)\n            (k): Linear(in_features=1024, out_features=1024, bias=False)\n            (v): Linear(in_features=1024, out_features=1024, bias=False)\n            (o): Linear(in_features=1024, out_features=1024, bias=False)\n            (relative_attention_bias): Embedding(32, 16)\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (1): T5LayerFF(\n          (DenseReluDense): T5DenseActDense(\n            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (act): ReLU()\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (1-23): 23 x T5Block(\n      (layer): ModuleList(\n        (0): T5LayerSelfAttention(\n          (SelfAttention): T5Attention(\n            (q): Linear(in_features=1024, out_features=1024, bias=False)\n            (k): Linear(in_features=1024, out_features=1024, bias=False)\n            (v): Linear(in_features=1024, out_features=1024, bias=False)\n            (o): Linear(in_features=1024, out_features=1024, bias=False)\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (1): T5LayerFF(\n          (DenseReluDense): T5DenseActDense(\n            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (act): ReLU()\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (final_layer_norm): T5LayerNorm()\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trained_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:55:05.587619Z","iopub.execute_input":"2025-09-26T14:55:05.588331Z","iopub.status.idle":"2025-09-26T14:55:05.594419Z","shell.execute_reply.started":"2025-09-26T14:55:05.588307Z","shell.execute_reply":"2025-09-26T14:55:05.593668Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"T5ForTokenClassification(\n  (transformer): T5EncoderModel(\n    (shared): Embedding(32128, 1024)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 1024)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=1024, out_features=1024, bias=False)\n                (k): Linear(in_features=1024, out_features=1024, bias=False)\n                (v): Linear(in_features=1024, out_features=1024, bias=False)\n                (o): Linear(in_features=1024, out_features=1024, bias=False)\n                (relative_attention_bias): Embedding(32, 16)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-23): 23 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=1024, out_features=1024, bias=False)\n                (k): Linear(in_features=1024, out_features=1024, bias=False)\n                (v): Linear(in_features=1024, out_features=1024, bias=False)\n                (o): Linear(in_features=1024, out_features=1024, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (dropout): Dropout(p=0.0, inplace=False)\n  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"trained_model.save_model(\"/kaggle/working/ruT5_large_260925_ft250925\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}